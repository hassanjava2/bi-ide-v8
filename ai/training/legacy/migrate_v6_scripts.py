"""
V6 Scripts Migration - ØªØ±Ø­ÙŠÙ„ Ø³ÙƒØ±Ø¨ØªØ§Øª v6
Migrate useful scripts from v6 to new structure

This script scans the v6-scripts directory, identifies useful scripts,
and migrates them to the new ai/training/ structure with updated imports.
"""

import json
import os
import shutil
import sys
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Set, Tuple, Optional
from dataclasses import dataclass, asdict
from enum import Enum
import logging

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class MigrationStatus(Enum):
    """Ø­Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠÙ„ - Migration status"""
    PENDING = "pending"
    SUCCESS = "success"
    FAILED = "failed"
    SKIPPED = "skipped"
    PARTIAL = "partial"


@dataclass
class ScriptInfo:
    """Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø³ÙƒØ±Ø¨Øª - Script information"""
    name: str
    source_path: Path
    target_path: Optional[Path]
    description: str
    features: List[str]
    status: MigrationStatus
    error_message: Optional[str] = None
    lines_of_code: int = 0


@dataclass
class MigrationReport:
    """ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªØ±Ø­ÙŠÙ„ - Migration report"""
    timestamp: str
    total_scripts: int
    migrated: int
    skipped: int
    failed: int
    partial: int
    scripts: List[Dict]


class V6MigrationTool:
    """
    Ø£Ø¯Ø§Ø© ØªØ±Ø­ÙŠÙ„ Ø³ÙƒØ±Ø¨ØªØ§Øª v6
    V6 Scripts Migration Tool
    
    ØªÙØ­Øµ Ø³ÙƒØ±Ø¨ØªØ§Øª v6 ÙˆØªØ­Ø¯Ø¯ Ù…Ø§ Ù‡Ùˆ Ù…ÙÙŠØ¯ Ù„Ù„ØªØ±Ø­ÙŠÙ„
    Scans v6 scripts and identifies useful ones for migration
    """
    
    # ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ø³ÙƒØ±Ø¨ØªØ§Øª Ù„Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
    # Script to target mapping
    MIGRATION_MAP: Dict[str, Tuple[str, List[str]]] = {
        "finetune.py": ("advanced_trainer.py", ["base_training", "lora", "completion"]),
        "finetune-chat.py": ("advanced_trainer.py", ["chat_training", "chatml", "conversation"]),
        "finetune-extended.py": ("advanced_trainer.py", ["extended_training", "data_augmentation", "deep_learning"]),
        "evaluate-model.py": ("evaluation_engine.py", ["perplexity", "model_evaluation"]),
        "validate-data.py": ("evaluation_engine.py", ["data_validation", "quality_check"]),
        "continuous-train.py": ("continuous_trainer.py", ["auto_trigger", "pipeline", "curriculum"]),
        "auto-finetune.py": ("continuous_trainer.py", ["idle_training", "background", "auto_conditions"]),
        "convert-to-gguf.py": ("model_converter.py", ["gguf", "llamacpp", "quantization"]),
        "convert-to-onnx.py": ("model_converter.py", ["onnx", "optimum", "export"]),
        "prepare-chat-data.py": (None, ["data_preparation", "chatml"]),  # Ù…Ø¯Ù…Ø¬ ÙÙŠ preprocessing
        "monitor.py": (None, ["monitoring", "reporting"]),  # ÙŠØ³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯
        "smart-learn.py": ("continuous_trainer.py", ["online_learning", "curriculum", "smart"]),
        "train_ai.py": ("advanced_trainer.py", ["comprehensive", "code_training", "patterns"]),
    }
    
    def __init__(
        self,
        v6_dir: Optional[Path] = None,
        target_dir: Optional[Path] = None
    ):
        """
        Initialize migration tool
        
        Args:
            v6_dir: Directory containing v6 scripts
            target_dir: Target directory for new structure
        """
        self.v6_dir = v6_dir or Path(__file__).parent.parent.parent.parent / "training" / "v6-scripts"
        self.target_dir = target_dir or Path(__file__).parent.parent
        self.legacy_dir = Path(__file__).parent
        
        self.scripts_info: List[ScriptInfo] = []
        self.report: Optional[MigrationReport] = None
        
        logger.info("=" * 60)
        logger.info("V6 Scripts Migration Tool")
        logger.info("ØªØ±Ø­ÙŠÙ„ Ø³ÙƒØ±Ø¨ØªØ§Øª Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ø³Ø§Ø¯Ø³")
        logger.info("=" * 60)
        logger.info(f"Source: {self.v6_dir}")
        logger.info(f"Target: {self.target_dir}")
        logger.info("")
    
    def scan_v6_scripts(self) -> List[ScriptInfo]:
        """
        ÙØ­Øµ Ø³ÙƒØ±Ø¨ØªØ§Øª v6
        Scan v6 scripts directory
        
        Returns:
            List of script information
        """
        logger.info("ğŸ” Scanning v6-scripts directory...")
        
        if not self.v6_dir.exists():
            logger.error(f"âŒ v6 directory not found: {self.v6_dir}")
            return []
        
        scripts = []
        for py_file in sorted(self.v6_dir.glob("*.py")):
            info = self._analyze_script(py_file)
            scripts.append(info)
            logger.info(f"  ğŸ“„ {py_file.name}: {info.lines_of_code} lines, {len(info.features)} features")
        
        self.scripts_info = scripts
        logger.info(f"\nğŸ“Š Found {len(scripts)} Python scripts")
        return scripts
    
    def _analyze_script(self, path: Path) -> ScriptInfo:
        """
        ØªØ­Ù„ÙŠÙ„ Ø³ÙƒØ±Ø¨Øª ÙØ±Ø¯ÙŠ
        Analyze a single script
        
        Args:
            path: Path to script
            
        Returns:
            Script information
        """
        try:
            content = path.read_text(encoding='utf-8')
            lines = len(content.splitlines())
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ÙˆØµÙ Ù…Ù† docstring
            # Extract description from docstring
            description = ""
            if '"""' in content:
                docstring = content.split('"""')[1] if '"""' in content else ""
                description = docstring.strip().split('\n')[0][:100]
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª
            # Identify features
            features = []
            if 'lora' in content.lower() or 'peft' in content.lower():
                features.append('lora')
            if 'chat' in content.lower() or 'conversation' in content.lower():
                features.append('chat')
            if 'onnx' in content.lower():
                features.append('onnx')
            if 'gguf' in content.lower():
                features.append('gguf')
            if 'evaluate' in content.lower():
                features.append('evaluation')
            if 'continuous' in content.lower() or 'auto' in content.lower():
                features.append('continuous')
            
            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù‡Ø¯Ù
            # Determine target
            target_file, mapped_features = self.MIGRATION_MAP.get(
                path.name, 
                (None, [])
            )
            target_path = self.target_dir / target_file if target_file else None
            
            return ScriptInfo(
                name=path.name,
                source_path=path,
                target_path=target_path,
                description=description,
                features=list(set(features + mapped_features)),
                status=MigrationStatus.PENDING,
                lines_of_code=lines
            )
            
        except Exception as e:
            return ScriptInfo(
                name=path.name,
                source_path=path,
                target_path=None,
                description=f"Error: {e}",
                features=[],
                status=MigrationStatus.FAILED,
                error_message=str(e),
                lines_of_code=0
            )
    
    def identify_useful_scripts(self) -> List[ScriptInfo]:
        """
        ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³ÙƒØ±Ø¨ØªØ§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø©
        Identify useful scripts for migration
        
        Returns:
            List of useful scripts
        """
        logger.info("\nğŸ¯ Identifying useful scripts...")
        
        useful = []
        for script in self.scripts_info:
            # Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„ØªØ­Ø¯ÙŠØ¯
            # Criteria for usefulness
            is_mapped = script.name in self.MIGRATION_MAP
            has_features = len(script.features) > 0
            not_deprecated = not any(
                keyword in script.name.lower() 
                for keyword in ['old', 'deprecated', 'test_', '_test']
            )
            
            if is_mapped and has_features and not_deprecated:
                useful.append(script)
                logger.info(f"  âœ… {script.name} â†’ {script.target_path.name if script.target_path else 'merged'}")
            else:
                script.status = MigrationStatus.SKIPPED
                logger.info(f"  â­ï¸  {script.name} (skipped)")
        
        logger.info(f"\nğŸ“‹ {len(useful)} scripts marked for migration")
        return useful
    
    def create_compatibility_layer(self) -> Path:
        """
        Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚
        Create compatibility layer
        
        Returns:
            Path to compatibility module
        """
        logger.info("\nğŸ”§ Creating compatibility layer...")
        
        compat_content = '''"""
V6 Compatibility Layer - Ø·Ø¨Ù‚Ø© ØªÙˆØ§ÙÙ‚ v6

Provides backward compatibility for code using v6 APIs.
ÙŠÙˆÙØ± ØªÙˆØ§ÙÙ‚Ø§Ù‹ Ù„Ù„ÙƒÙˆØ¯ Ø§Ù„Ø°ÙŠ ÙŠØ³ØªØ®Ø¯Ù… ÙˆØ§Ø¬Ù‡Ø§Øª v6.
"""

import warnings
from typing import Any, Optional
import sys
from pathlib import Path

# Add new training module to path
_training_module_path = Path(__file__).parent.parent
if str(_training_module_path) not in sys.path:
    sys.path.insert(0, str(_training_module_path))

# Import new modules with compatibility aliases
try:
    from ai.training.advanced_trainer import AdvancedTrainer
    from ai.training.evaluation_engine import EvaluationEngine
    from ai.training.continuous_trainer import ContinuousTrainer
    from ai.training.model_converter import ModelConverter
    V8_AVAILABLE = True
except ImportError:
    V8_AVAILABLE = False


class FineTuneV6:
    """
    Compatibility wrapper for finetune.py
    ØºÙ„Ø§Ù ØªÙˆØ§ÙÙ‚ Ù„Ù€ finetune.py
    """
    
    def __init__(self):
        warnings.warn(
            "FineTuneV6 is deprecated. Use AdvancedTrainer instead.",
            DeprecationWarning,
            stacklevel=2
        )
        if V8_AVAILABLE:
            self._trainer = AdvancedTrainer()
        else:
            raise ImportError("V8 training module not available")
    
    def train(self, *args, **kwargs) -> Any:
        """Delegate to AdvancedTrainer"""
        return self._trainer.train(*args, **kwargs)


class FineTuneChatV6:
    """
    Compatibility wrapper for finetune-chat.py
    ØºÙ„Ø§Ù ØªÙˆØ§ÙÙ‚ Ù„Ù€ finetune-chat.py
    """
    
    def __init__(self):
        warnings.warn(
            "FineTuneChatV6 is deprecated. Use AdvancedTrainer with mode='chat'.",
            DeprecationWarning,
            stacklevel=2
        )
        if V8_AVAILABLE:
            self._trainer = AdvancedTrainer(mode='chat')
        else:
            raise ImportError("V8 training module not available")
    
    def train(self, *args, **kwargs) -> Any:
        """Delegate to AdvancedTrainer"""
        return self._trainer.train(*args, **kwargs)


class EvaluateModelV6:
    """
    Compatibility wrapper for evaluate-model.py
    ØºÙ„Ø§Ù ØªÙˆØ§ÙÙ‚ Ù„Ù€ evaluate-model.py
    """
    
    def __init__(self):
        warnings.warn(
            "EvaluateModelV6 is deprecated. Use EvaluationEngine instead.",
            DeprecationWarning,
            stacklevel=2
        )
        if V8_AVAILABLE:
            self._engine = EvaluationEngine()
        else:
            raise ImportError("V8 training module not available")
    
    def evaluate(self, *args, **kwargs) -> Any:
        """Delegate to EvaluationEngine"""
        return self._engine.evaluate_model(*args, **kwargs)


class ContinuousTrainV6:
    """
    Compatibility wrapper for continuous-train.py
    ØºÙ„Ø§Ù ØªÙˆØ§ÙÙ‚ Ù„Ù€ continuous-train.py
    """
    
    def __init__(self):
        warnings.warn(
            "ContinuousTrainV6 is deprecated. Use ContinuousTrainer instead.",
            DeprecationWarning,
            stacklevel=2
        )
        if V8_AVAILABLE:
            self._trainer = ContinuousTrainer()
        else:
            raise ImportError("V8 training module not available")
    
    def start(self, *args, **kwargs) -> Any:
        """Delegate to ContinuousTrainer"""
        return self._trainer.start(*args, **kwargs)


def migrate_v6_config(config: dict) -> dict:
    """
    Convert v6 config format to v8
    ØªØ­ÙˆÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª v6 Ø¥Ù„Ù‰ v8
    
    Args:
        config: V6 configuration dict
        
    Returns:
        V8 configuration dict
    """
    mapping = {
        'MODEL_NAME': 'model_name',
        'MAX_LENGTH': 'max_length',
        'BATCH_SIZE': 'batch_size',
        'EPOCHS': 'epochs',
        'LEARNING_RATE': 'learning_rate',
        'LORA_R': 'lora_r',
        'LORA_ALPHA': 'lora_alpha',
        'NUM_WORKERS': 'num_workers',
    }
    
    return {
        mapping.get(k, k): v 
        for k, v in config.items()
    }


# Export compatibility classes
__all__ = [
    'FineTuneV6',
    'FineTuneChatV6', 
    'EvaluateModelV6',
    'ContinuousTrainV6',
    'migrate_v6_config',
    'V8_AVAILABLE',
]
'''
        
        compat_path = self.legacy_dir / "v6_compatibility.py"
        compat_path.write_text(compat_content, encoding='utf-8')
        
        logger.info(f"  âœ… Created: {compat_path}")
        return compat_path
    
    def log_migration_status(self) -> Path:
        """
        ØªØ³Ø¬ÙŠÙ„ Ø­Ø§Ù„Ø© Ø§Ù„ØªØ±Ø­ÙŠÙ„
        Log migration status
        
        Returns:
            Path to log file
        """
        log_path = self.legacy_dir / "migration_log.json"
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        # Calculate statistics
        total = len(self.scripts_info)
        migrated = sum(1 for s in self.scripts_info if s.status == MigrationStatus.SUCCESS)
        skipped = sum(1 for s in self.scripts_info if s.status == MigrationStatus.SKIPPED)
        failed = sum(1 for s in self.scripts_info if s.status == MigrationStatus.FAILED)
        partial = sum(1 for s in self.scripts_info if s.status == MigrationStatus.PARTIAL)
        
        self.report = MigrationReport(
            timestamp=datetime.now().isoformat(),
            total_scripts=total,
            migrated=migrated,
            skipped=skipped,
            failed=failed,
            partial=partial,
            scripts=[
                {
                    **asdict(script),
                    'status': script.status.value,
                    'source_path': str(script.source_path),
                    'target_path': str(script.target_path) if script.target_path else None
                }
                for script in self.scripts_info
            ]
        )
        
        with open(log_path, 'w', encoding='utf-8') as f:
            json.dump(asdict(self.report), f, ensure_ascii=False, indent=2)
        
        logger.info(f"\nğŸ“ Migration log saved: {log_path}")
        return log_path
    
    def generate_migration_summary(self) -> str:
        """
        ØªÙˆÙ„ÙŠØ¯ Ù…Ù„Ø®Øµ Ø§Ù„ØªØ±Ø­ÙŠÙ„
        Generate migration summary
        
        Returns:
            Summary string
        """
        if not self.report:
            return "No migration report available."
        
        summary = f"""
{'=' * 60}
V6 Migration Summary | Ù…Ù„Ø®Øµ ØªØ±Ø­ÙŠÙ„ v6
{'=' * 60}

Timestamp: {self.report.timestamp}

Statistics:
  ğŸ“Š Total scripts: {self.report.total_scripts}
  âœ… Migrated: {self.report.migrated}
  â­ï¸  Skipped: {self.report.skipped}
  âš ï¸  Failed: {self.report.failed}
  ğŸ”„ Partial: {self.report.partial}

New Structure:
  ğŸ“ ai/training/advanced_trainer.py
     â””â”€ Merged: finetune.py, finetune-chat.py, finetune-extended.py
  
  ğŸ“ ai/training/evaluation_engine.py
     â””â”€ Merged: evaluate-model.py, validate-data.py
  
  ğŸ“ ai/training/continuous_trainer.py
     â””â”€ Merged: continuous-train.py, auto-finetune.py, smart-learn.py
  
  ğŸ“ ai/training/model_converter.py
     â””â”€ Merged: convert-to-gguf.py, convert-to-onnx.py
  
  ğŸ“ ai/training/multi_gpu_trainer.py
     â””â”€ New: Distributed training with PyTorch 2.x DDP
  
  ğŸ“ ai/training/legacy/v6_compatibility.py
     â””â”€ Compatibility layer for backward compatibility

Key Improvements:
  â€¢ PyTorch 2.x support
  â€¢ CUDA 12.x compatibility
  â€¢ Type hints throughout
  â€¢ Arabic/English docstrings
  â€¢ Unified logging
  â€¢ Better error handling
  â€¢ LoRA support in all trainers
  â€¢ Mixed precision training

{'=' * 60}
"""
        return summary
    
    def run_full_migration(self) -> MigrationReport:
        """
        ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ±Ø­ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„
        Run full migration process
        
        Returns:
            Migration report
        """
        logger.info("\n" + "=" * 60)
        logger.info("Starting Full Migration Process")
        logger.info("Ø¨Ø¯Ø¡ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ØªØ±Ø­ÙŠÙ„ Ø§Ù„ÙƒØ§Ù…Ù„Ø©")
        logger.info("=" * 60 + "\n")
        
        # 1. ÙØ­Øµ Ø§Ù„Ø³ÙƒØ±Ø¨ØªØ§Øª
        self.scan_v6_scripts()
        
        # 2. ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø³ÙƒØ±Ø¨ØªØ§Øª Ø§Ù„Ù…ÙÙŠØ¯Ø©
        useful = self.identify_useful_scripts()
        
        # 3. Ø¥Ù†Ø´Ø§Ø¡ Ø·Ø¨Ù‚Ø© Ø§Ù„ØªÙˆØ§ÙÙ‚
        self.create_compatibility_layer()
        
        # 4. ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø³ÙƒØ±Ø¨ØªØ§Øª Ø§Ù„Ù…Ø¯Ù…Ø¬Ø©
        for script in useful:
            if script.target_path:
                script.status = MigrationStatus.SUCCESS
            else:
                script.status = MigrationStatus.PARTIAL
        
        # 5. ØªØ³Ø¬ÙŠÙ„ Ø§Ù„Ø­Ø§Ù„Ø©
        self.log_migration_status()
        
        # 6. Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„Ù…Ù„Ø®Øµ
        summary = self.generate_migration_summary()
        logger.info(summary)
        
        # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ø®Øµ
        summary_path = self.legacy_dir / "MIGRATION_SUMMARY.txt"
        summary_path.write_text(summary, encoding='utf-8')
        
        logger.info(f"\nâœ… Migration complete!")
        logger.info(f"   Summary: {summary_path}")
        logger.info(f"   Log: {self.legacy_dir / 'migration_log.json'}")
        
        return self.report


def main():
    """Main entry point for migration"""
    tool = V6MigrationTool()
    report = tool.run_full_migration()
    return 0 if report and report.failed == 0 else 1


if __name__ == "__main__":
    sys.exit(main())
