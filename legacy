"""
Smart Council - Ù…Ø¬Ù„Ø³ Ø§Ù„Ø­ÙƒÙ…Ø§Ø¡ Ø§Ù„Ø°ÙƒÙŠ
ÙƒÙ„ Ø­ÙƒÙŠÙ… Ø¹Ø¨Ø§Ø±Ø© Ø¹Ù† AI Transformer Ø­Ù‚ÙŠÙ‚ÙŠ Ù…Ù†ÙØµÙ„
"""
import torch
import torch.nn as nn
import json
import re
from pathlib import Path
from typing import List, Dict, Optional
import random
import hashlib
from datetime import datetime
import asyncio

# Import Wise AI Engine
from wise_ai_engine import wise_ai_engine

# Import RTX 4090 Client
try:
    from ai.rtx4090_client import RTX4090Client, RTX4090Pool
    RTX4090_AVAILABLE = True
except ImportError:
    RTX4090_AVAILABLE = False

CHECKPOINT_DIR = Path("learning_data/checkpoints")


class KnowledgeBaseLoader:
    """Loads and indexes training knowledge base for code error patterns"""
    _instance = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._loaded = False
        return cls._instance
    
    def __init__(self):
        if self._loaded:
            return
        self._loaded = True
        self.patterns = []
        self.by_language = {}
        self.by_category = {}
        self._load()
    
    def _load(self):
        """Load knowledge-base.json from models/"""
        kb_path = Path(__file__).parent / 'models' / 'knowledge-base.json'
        if not kb_path.exists():
            print("  [!] knowledge-base.json not found - running without KB")
            return
        try:
            data = json.loads(kb_path.read_text(encoding='utf-8'))
            raw_patterns = data.get('error_patterns', [])
            for p in raw_patterns:
                lang = p.get('language', p.get('metadata', {}).get('language', 'unknown'))
                cat = p.get('category', p.get('error_type', p.get('metadata', {}).get('category', 'general')))
                entry = {
                    'input': p.get('input', p.get('instruction', '')),
                    'output': p.get('output', ''),
                    'language': lang,
                    'category': cat,
                }
                self.patterns.append(entry)
                self.by_language.setdefault(lang, []).append(entry)
                self.by_category.setdefault(cat, []).append(entry)
            print(f"  [OK] Knowledge base loaded: {len(self.patterns)} error patterns")
        except Exception as e:
            print(f"  [!] Failed to load knowledge-base: {e}")
    
    def search(self, message: str, top_k: int = 3) -> List[Dict]:
        """Search for relevant patterns by keyword matching"""
        if not self.patterns:
            return []
        msg_lower = message.lower()
        
        # Detect language from message
        lang_keywords = {
            'javascript': ['javascript', 'js', 'const ', 'let ', 'var ', 'function ', 'console.', '=>', 'async ', 'await '],
            'python': ['python', 'def ', 'import ', 'class ', 'self.', 'print(', 'elif', '__init__'],
            'react': ['react', 'usestate', 'useeffect', 'jsx', 'component', 'hooks', '<div'],
            'java': ['java', 'public ', 'private ', 'void ', 'string ', 'system.out'],
            'cpp': ['c++', 'cpp', 'cout', 'cin', 'nullptr', 'std::'],
            'sql': ['sql', 'select ', 'insert ', 'update ', 'delete ', 'from ', 'where '],
        }
        detected_lang = None
        for lang, keywords in lang_keywords.items():
            if any(kw in msg_lower for kw in keywords):
                detected_lang = lang
                break
        
        # Score patterns by relevance
        scored = []
        search_pool = self.by_language.get(detected_lang, self.patterns) if detected_lang else self.patterns
        
        for p in search_pool:
            input_text = p['input'].lower()
            output_text = p['output'].lower()
            # Simple keyword overlap scoring
            msg_words = set(re.findall(r'\w+', msg_lower))
            pattern_words = set(re.findall(r'\w+', input_text + ' ' + output_text))
            overlap = len(msg_words & pattern_words)
            if overlap >= 2:  # At least 2 word overlap
                scored.append((overlap, p))
        
        scored.sort(key=lambda x: x[0], reverse=True)
        return [p for _, p in scored[:top_k]]


# Global knowledge base singleton
try:
    knowledge_base = KnowledgeBaseLoader()
except Exception:
    knowledge_base = None


class WiseManTransformer(nn.Module):
    """Transformer model Ù„ÙƒÙ„ Ø­ÙƒÙŠÙ…"""
    def __init__(self, vocab_size=10000, d_model=256, nhead=8, num_layers=4):
        super().__init__()
        self.d_model = d_model
        self.embedding = nn.Embedding(vocab_size, d_model)
        self.pos_encoder = nn.Embedding(512, d_model)
        
        encoder_layers = nn.TransformerEncoderLayer(
            d_model=d_model, 
            nhead=nhead,
            dim_feedforward=d_model*4,
            batch_first=True
        )
        self.transformer = nn.TransformerEncoder(encoder_layers, num_layers)
        self.fc = nn.Linear(d_model, vocab_size)
        
    def forward(self, x):
        # x: (batch, seq_len)
        seq_len = x.size(1)
        positions = torch.arange(seq_len, device=x.device).unsqueeze(0)
        
        x = self.embedding(x) + self.pos_encoder(positions)
        x = self.transformer(x)
        return self.fc(x)


class WiseManAI:
    """Ø­ÙƒÙŠÙ… ÙˆØ§Ø­Ø¯ - AI Ù…Ù†ÙØµÙ„ Ø¨Ø´Ø®ØµÙŠØªÙ‡ Ø§Ù„Ø®Ø§ØµØ©"""
    
    def __init__(self, name: str, role: str, specialty: str, checkpoint_path: Optional[Path] = None):
        self.name = name
        self.role = role
        self.specialty = specialty
        self.checkpoint_path = checkpoint_path
        self.model = None
        # Use persistent memory store instead of in-memory list
        from council_memory import council_memory
        self.memory_store = council_memory
        self.session_id = hashlib.md5(f"{name}_{datetime.now().isoformat()}".encode()).hexdigest()[:16]
        self.last_generation_meta: Dict = {
            'source': 'persona-template',
            'confidence': 0.4,
            'evidence': []
        }
        self.personality = self._get_personality()
        
        # Ø­Ø§ÙˆÙ„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
        if checkpoint_path and checkpoint_path.exists():
            self._load_model()
        else:
            print(f"  [!] {name}: using personality-based responses (no model)")
    
    def _get_personality(self) -> Dict:
        """Ø´Ø®ØµÙŠØ© Ø§Ù„Ø­ÙƒÙŠÙ…"""
        personalities = {
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±': {
                'style': 'Ø­Ø§Ø²Ù… ÙˆÙˆØ§Ø¶Ø­',
                'greeting': 'Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ØŒ Ø£Ù†Ø§ Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±. Ù…Ø§ Ù‡Ùˆ Ù‚Ø±Ø§Ø±ÙƒØŸ',
                'traits': ['decisive', 'strategic', 'leader']
            },
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø©': {
                'style': 'Ø¹Ù…ÙŠÙ‚ ÙˆØªØ­Ù„ÙŠÙ„ÙŠ',
                'greeting': 'Ø£Ø±Ù‰ Ù…Ø§ Ù„Ø§ ØªØ±Ø§Ù‡ Ø§Ù„Ø¹ÙŠÙˆÙ†. Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø¨Ù…Ø§ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡.',
                'traits': ['analytical', 'deep', 'insightful']
            },
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„': {
                'style': 'Ø±Ø¤ÙŠÙˆÙŠ ÙˆØ¨Ø¹ÙŠØ¯ Ø§Ù„Ù†Ø¸Ø±',
                'greeting': 'Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ ÙŠÙƒØ´Ù Ø£Ø³Ø±Ø§Ø±Ù‡ Ù„Ù…Ù† ÙŠØµØ¨Ø±. Ù…Ø§ Ø±Ø¤ÙŠØªÙƒØŸ',
                'traits': ['visionary', 'patient', 'long-term']
            },
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©': {
                'style': 'Ø¬Ø±ÙŠØ¡ ÙˆØ­Ø§Ø³Ù…',
                'greeting': 'Ø§Ù„Ø´Ø¬Ø§Ø¹Ø© Ù„ÙŠØ³Øª ØºÙŠØ§Ø¨ Ø§Ù„Ø®ÙˆÙØŒ Ø¨Ù„ Ø§Ù„ØªØ­Ø±Ø± Ø±ØºÙ… Ø§Ù„Ø®ÙˆÙ.',
                'traits': ['brave', 'bold', 'action-oriented']
            },
            'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù†': {
                'style': 'Ø¹Ø§Ø¯Ù„ ÙˆÙ…ØªØ²Ù†',
                'greeting': 'Ø§Ù„Ø¹Ø¯Ù„ Ø£Ø³Ø§Ø³ Ø§Ù„Ù…Ù„Ùƒ. Ø£Ø¹Ø±Ø¶ Ø¹Ù„ÙŠ Ù‚Ø¶ÙŠØªÙƒ.',
                'traits': ['fair', 'balanced', 'just']
            },
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø·': {
                'style': 'Ø¯Ù‚ÙŠÙ‚ ÙˆÙ…Ù†Ø¸Ù…',
                'greeting': 'Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù…ÙŠ Ù…Ù† Ø§Ù„ÙÙˆØ¶Ù‰. ÙƒÙŠÙ Ø£Ø®Ø¯Ù…ÙƒØŸ',
                'traits': ['organized', 'precise', 'protective']
            },
            'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ': {
                'style': 'Ù…Ø±Ù† ÙˆØ°ÙƒÙŠ',
                'greeting': 'Ø§Ù„ØªØºÙŠÙŠØ± Ù‡Ùˆ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ÙˆØ­ÙŠØ¯ Ø§Ù„Ø«Ø§Ø¨Øª.',
                'traits': ['adaptive', 'smart', 'flexible']
            },
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø©': {
                'style': 'Ø­ÙƒÙŠÙ… ÙˆØ°Ùˆ Ø®Ø¨Ø±Ø©',
                'greeting': 'Ù…Ù† Ø§Ù„ØªØ§Ø±ÙŠØ® Ù†ØªØ¹Ù„Ù…ØŒ ÙˆÙ…Ù† Ø§Ù„Ø®Ø¨Ø±Ø© Ù†Ø­ÙƒÙ….',
                'traits': ['experienced', 'wise', 'historical']
            }
        }
        return personalities.get(self.name, {
            'style': 'Ø­ÙƒÙŠÙ… ÙˆÙ…ØªÙˆØ§Ø¶Ø¹',
            'greeting': 'Ø£Ù†Ø§ ÙÙŠ Ø®Ø¯Ù…ØªÙƒØŒ Ø³ÙŠØ§Ø¯Ø© Ø§Ù„Ø±Ø¦ÙŠØ³.',
            'traits': ['wise', 'helpful']
        })
    
    def _load_model(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ù† Checkpoint"""
        try:
            checkpoint = torch.load(self.checkpoint_path, map_location='cpu', weights_only=False)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆØ²Ø§Ù†
            self.model = WiseManTransformer()
            self.model.load_state_dict(checkpoint['model_state'])
            self.model.eval()
            
            print(f"  [OK] {self.name}: AI model loaded (trained {checkpoint.get('epoch', 0)} epochs)")
        except Exception as e:
            print(f"  [!] {self.name}: Could not load model ({e})")
            self.model = None
    
    def _build_prompt(self, message: str) -> str:
        """Build contextual prompt for the wise man with personality and memory"""
        personality = self.personality['style']
        traits = ", ".join(self.personality.get('traits', ['Ø­ÙƒÙŠÙ…']))
        
        # Get recent conversation history
        try:
            recent_history = self.memory_store.get_conversation_history(
                self.name, self.session_id, limit=5
            )
            context = "\n".join([
                f"{m.get('role', 'unknown')}: {m.get('message', '')}"
                for m in recent_history[-5:]
            ]) if recent_history else "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ø³Ø§Ø¨Ù‚."
        except:
            context = "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø³ÙŠØ§Ù‚ Ø³Ø§Ø¨Ù‚."
        
        prompt = f"""Ø£Ù†Øª {self.name}ØŒ {self.role}.
Ø´Ø®ØµÙŠØªÙƒ: {personality}
ØµÙØ§ØªÙƒ: {traits}

Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚:
{context}

Ø§Ù„Ø³Ø¤Ø§Ù„: {message}

Ù‚Ø¯Ù… Ø±Ø£ÙŠØ§Ù‹ Ø­ÙƒÙŠÙ…Ø§Ù‹ ÙˆÙ…ÙÙŠØ¯Ø§Ù‹ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø§Ù„ÙØµØ­Ù‰:"""
        
        return prompt
    
    async def think_with_rtx4090(self, message: str, **kwargs) -> Dict[str, any]:
        """
        Use RTX 4090 for real AI inference
        
        Args:
            message: User message
            **kwargs: Additional parameters for generation
        
        Returns:
            Dict with response and metadata
        """
        if not RTX4090_AVAILABLE:
            return {
                "response": self._generate_response(message, message.lower()),
                "source": "personality-fallback",
                "confidence": 0.4,
                "rtx_available": False
            }
        
        # Build prompt with personality and context
        prompt = self._build_prompt(message)
        
        # Call RTX 4090
        try:
            async with RTX4090Client() as client:
                response = await client.generate_text(
                    prompt=prompt,
                    max_tokens=kwargs.get('max_tokens', 512),
                    temperature=kwargs.get('temperature', 0.8),
                    top_p=kwargs.get('top_p', 0.9)
                )
                
                return {
                    "response": response,
                    "source": "rtx4090-inference",
                    "confidence": 0.85,
                    "rtx_available": True,
                    "wise_man": self.name
                }
        except Exception as e:
            # Fallback to template-based response
            fallback_response = self._generate_response(message, message.lower())
            return {
                "response": fallback_response,
                "source": "rtx4090-fallback",
                "confidence": 0.5,
                "rtx_available": False,
                "rtx_error": str(e),
                "wise_man": self.name
            }
    
    def think_with_rtx4090_sync(self, message: str, **kwargs) -> Dict[str, any]:
        """Synchronous wrapper for think_with_rtx4090"""
        try:
            return asyncio.run(self.think_with_rtx4090(message, **kwargs))
        except Exception as e:
            # Fallback on any error
            return {
                "response": self._generate_response(message, message.lower()),
                "source": "fallback-error",
                "confidence": 0.4,
                "rtx_available": False,
                "error": str(e)
            }
    
    def think(self, message: str, context: List[Dict] = None, strict_evidence: bool = False) -> str:
        """Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ø±Ø¯ ÙƒØ¥Ù†Ø³Ø§Ù† Ø­Ù‚ÙŠÙ‚ÙŠ"""
        
        # Ø­ÙØ¸ Ø¨Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ø§Ø¦Ù…Ø©
        self.memory_store.store_message(
            wise_man_name=self.name,
            role='president',
            message=message,
            session_id=self.session_id
        )
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø³ÙŠØ§Ù‚
        msg_lower = message.lower()
        
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø±Ø¯ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø®ØµÙŠØ© ÙˆØ§Ù„Ø³ÙŠØ§Ù‚
        response = self._generate_response(message, msg_lower, strict_evidence=strict_evidence)

        if strict_evidence and not response:
            # Evidence blocked - don't save to memory
            return ''
        
        # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¯Ø§Ø¦Ù…Ø©
        self.memory_store.store_message(
            wise_man_name=self.name,
            role=self.name,
            message=response,
            session_id=self.session_id,
            metadata=self.last_generation_meta
        )
        
        return response
    
    def _generate_response(self, message: str, msg_lower: str, strict_evidence: bool = False) -> str:
        """ØªÙˆÙ„ÙŠØ¯ Ø±Ø¯ Ø°ÙƒÙŠ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø®ØµÙŠØ© + Inference Engine"""
        
        # âœ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Wise AI Engine (Hybrid System)
        try:
            ai_result = wise_ai_engine.generate_response_with_evidence(
                message=message,
                wise_man_name=self.name,
                conversation_history=[m.get('message', '') for m in 
                                     self.memory_store.get_conversation_history(self.name, self.session_id, limit=20)
                                     if m.get('role') == self.name],
                strict_evidence=strict_evidence
            )
            self.last_generation_meta = {
                'source': ai_result.get('source', 'training+persona'),
                'confidence': ai_result.get('confidence', 0.65),
                'evidence': ai_result.get('evidence', []),
                'blocked': ai_result.get('blocked', False)
            }
            if strict_evidence and ai_result.get('blocked'):
                return ''
            return ai_result.get('response', self.personality['greeting'])
        except Exception as e:
            print(f"  [!] Wise AI error for {self.name}: {str(e)[:50]}")
            self.last_generation_meta = {
                'source': 'personality-fallback',
                'confidence': 0.3,
                'evidence': []
            }
        
        # ðŸ§  Second tier: Knowledge Base patterns (516 error patterns)
        if knowledge_base:
            kb_results = knowledge_base.search(message, top_k=3)
            if kb_results:
                best = kb_results[0]
                kb_response = best['output']
                if kb_response:
                    self.last_generation_meta = {
                        'source': f'knowledge-base ({best["language"]}/{best["category"]})',
                        'confidence': 0.7,
                        'evidence': [{'type': 'training-pattern', 'language': best['language'], 'category': best['category']}]
                    }
                    return kb_response
    
        # Fallback: Ø±Ø¯ÙˆØ¯ Ù…Ø®ØµØµØ© Ù„ÙƒÙ„ Ø­ÙƒÙŠÙ…
        responses = self._get_personality_responses(msg_lower)
        
        # Ø¥Ø¶Ø§ÙØ© Ù„Ù…Ø³Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© (Ø°Ø§ÙƒØ±Ø© Ù‚ØµÙŠØ±Ø©)
        recent_history = self.memory_store.get_conversation_history(self.name, self.session_id, limit=3)
        if len(recent_history) >= 2:
            last_topic = recent_history[-2].get('message', '')
            if any(word in last_topic for word in ['ØªØ­Ù„ÙŠÙ„', 'ØªÙ‚Ø±ÙŠØ±', 'Ø¨ÙŠØ§Ù†Ø§Øª']):
                responses.append(f"ÙƒÙ…Ø§ Ø°ÙƒØ±Øª Ø³Ø§Ø¨Ù‚Ø§Ù‹ØŒ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…ÙŠÙ‚ ÙŠÙƒØ´Ù Ø§Ù„Ø­Ù‚ÙŠÙ‚Ø©.")
        
        self.last_generation_meta = {
            'source': 'personality-fallback',
            'confidence': 0.35,
            'evidence': []
        }
        return random.choice(responses) if responses else self.personality['greeting']
    
    def _get_personality_responses(self, msg_lower: str) -> List[str]:
        """Ø±Ø¯ÙˆØ¯ Ø­Ø³Ø¨ Ø§Ù„Ø´Ø®ØµÙŠØ© ÙˆØ§Ù„Ø³ÙŠØ§Ù‚"""
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø± - Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ
        if self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±':
            if any(w in msg_lower for w in ['Ù‚Ø±Ø§Ø±', 'Ù†ÙØ°', 'Ø³ÙˆÙŠ', '(strategy|decision|do)']):
                return [
                    "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ÙŠØŒ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø£Ù…Ø«Ù„ Ù‡Ùˆ Ø§Ù„ØªÙ†ÙˆÙŠØ¹. Ù„Ø§ ØªØ¶Ø¹ ÙƒÙ„ Ø«Ù‚ØªÙƒ Ø¨Ø®ÙŠØ§Ø± ÙˆØ§Ø­Ø¯.",
                    "Ø£Ù†ØµØ­Ùƒ Ø¨Ø§Ù„ØµØ¨Ø±. Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„ÙƒØ¨Ø±Ù‰ ØªØ­ØªØ§Ø¬ ØªÙÙƒÙŠØ±Ø§Ù‹ Ø¹Ù…ÙŠÙ‚Ø§Ù‹.",
                    "Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø­ÙƒÙŠÙ… ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ§Ù„Ø­Ø¯Ø³. Ù…Ø§ Ù‡ÙŠ Ø¨ÙŠØ§Ù†Ø§ØªÙƒØŸ"
                ]
            return [
                "Ø£Ù†Ø§ Ù‡Ù†Ø§ Ù„Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø¹Ù„Ù‰ Ø§ØªØ®Ø§Ø° Ø£ÙØ¶Ù„ Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª.",
                "Ù…Ø§ Ù‡Ùˆ Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ø°ÙŠ ØªÙˆØ§Ø¬Ù‡Ù‡ØŸ Ø¯Ø¹Ù†ÙŠ Ø£Ø³Ø§Ø¹Ø¯Ùƒ Ø¨Ø§Ù„ØªØ­Ù„ÙŠÙ„."
            ]
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø© - ØªØ­Ù„ÙŠÙ„ÙŠ
        elif self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø©':
            if any(w in msg_lower for w in ['ØªØ­Ù„ÙŠÙ„', 'ØªÙ‚Ø±ÙŠØ±', 'Ø¨ÙŠØ§Ù†Ø§Øª', '(analysis|report|data)']):
                return [
                    "Ø£Ø±Ù‰ ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ù…Ø·Ø§Ù‹ Ù…Ù‚Ù„Ù‚Ø§Ù‹. Ø§Ù„ØªØ±ÙƒÙŠØ² Ø§Ù„Ø²Ø§Ø¦Ø¯ Ø¹Ù„Ù‰ Ø¬Ø§Ù†Ø¨ ÙˆØ§Ø­Ø¯ ÙŠØ®ÙÙŠ Ø§Ù„Ù…Ø®Ø§Ø·Ø±.",
                    "ØªØ­Ù„ÙŠÙ„ÙŠ ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ ÙØ±ØµØ© ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ Ù„Ù… ØªÙ„Ø­Ø¸Ù‡Ø§ Ø¨Ø¹Ø¯. Ù‡Ù„ ØªØ±ÙŠØ¯ Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŸ",
                    "Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ø§ ØªÙƒØ°Ø¨ØŒ Ù„ÙƒÙ†Ù‡Ø§ ØªØ­ØªØ§Ø¬ Ù…Ù† ÙŠÙÙ‡Ù… Ù„ØºØªÙ‡Ø§."
                ]
            return [
                "Ø£Ø±Ù‰ Ù…Ø§ ÙˆØ±Ø§Ø¡ Ø§Ù„Ø¸ÙˆØ§Ù‡Ø±. Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù…Ø§ ÙŠÙ‚Ù„Ù‚Ùƒ.",
                "Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ØªØ®Ø¨Ø±Ù†ÙŠ Ø¨Ù‚ØµØ©. Ù…Ø§ Ø§Ù„Ù‚ØµØ© Ø§Ù„ØªÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡Ø§ØŸ"
            ]
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ - Ø±Ø¤ÙŠÙˆÙŠ
        elif self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„':
            if any(w in msg_lower for w in ['Ù…Ø³ØªÙ‚Ø¨Ù„', 'Ø®Ø·Ø·', 'Ø³Ù†Ø©', '(future|plan|next year)']):
                return [
                    "Ø±Ø¤ÙŠØªÙŠ Ù„Ù„Ù…Ø³ØªÙ‚Ø¨Ù„: Ø§Ù„ØªÙƒÙŠÙ Ø§Ù„ØªÙ‚Ù†ÙŠ Ø³ÙŠÙØµÙ„ Ø§Ù„Ù†Ø§Ø¬Ø­ÙŠÙ† Ø¹Ù† Ø§Ù„Ø¨Ø§Ù‚ÙŠÙ†. Ø§Ø³ØªØ¹Ø¯ Ø§Ù„Ø¢Ù†.",
                    "Ø§Ù„Ø®Ø·Ø· Ø§Ù„Ø®Ù…Ø³ÙŠØ© Ù†Ø§Ø¬Ø­Ø© ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ù…Ø±Ù†Ø©. rigidity ØªÙ‚ØªÙ„ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„.",
                    "Ø£Ø±Ù‰ ÙØ±ØµØ© ÙƒØ¨ÙŠØ±Ø© ÙÙŠ Ø§Ù„Ø³ÙˆÙ‚ Ø®Ù„Ø§Ù„ 6 Ø£Ø´Ù‡Ø±. Ù‡Ù„ Ø£Ù†Øª Ù…Ø³ØªØ¹Ø¯ØŸ"
                ]
            return [
                "Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„ Ù„ÙŠØ³ Ù…ÙƒØªÙˆØ¨Ø§Ù‹ØŒ Ù†Ø­Ù† Ù…Ù† Ù†ÙƒØªØ¨Ù‡ Ø¨Ù‚Ø±Ø§Ø±Ø§ØªÙ†Ø§ Ø§Ù„ÙŠÙˆÙ….",
                "Ù…Ø§ Ù‡ÙŠ Ø±Ø¤ÙŠØªÙƒ Ù„Ù„Ø³Ù†ÙˆØ§Øª Ø§Ù„Ù‚Ø§Ø¯Ù…Ø©ØŸ"
            ]
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø© - Ø¬Ø±ÙŠØ¡
        elif self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©':
            if any(w in msg_lower for w in ['Ø®Ø·Ø±', 'Ù…Ø´ÙƒÙ„Ø©', 'Ø£Ø²Ù…Ø©', '(risk|crisis|problem)']):
                return [
                    "Ø§Ù„Ø®Ø·Ø± Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ù„ÙŠØ³ ÙÙŠ Ø§Ù„ÙØ¹Ù„ØŒ Ø¨Ù„ ÙÙŠ Ø§Ù„Ø¬Ù…ÙˆØ¯. ØªØ­Ø±Ùƒ Ø§Ù„Ø¢Ù†!",
                    "Ø§Ù„Ø´Ø¬Ø§Ø¹Ø© ØªÙ‚ØªØ¶ÙŠ Ø§Ù„Ø§Ø¹ØªØ±Ø§Ù Ø¨Ø§Ù„Ù…Ø´ÙƒÙ„Ø© ÙˆØ§Ù„Ù…ÙˆØ§Ø¬Ù‡Ø©. Ø£Ù†Ø§ Ù…Ø¹Ùƒ.",
                    "ÙƒÙ„ Ø£Ø²Ù…Ø© ØªØ­Ù…Ù„ ÙØ±ØµØ©. Ø¯Ø¹Ù†Ø§ Ù†Ø³ØªØºÙ„ Ù‡Ø°Ù‡ Ø§Ù„ÙØ±ØµØ©."
                ]
            return [
                "Ø£Ø­ÙŠØ§Ù†Ø§Ù‹ ÙŠØ¬Ø¨ Ø£Ù† Ù†Ù‚ÙØ² Ù‚Ø¨Ù„ Ø£Ù† Ù†ÙƒÙˆÙ† Ø¬Ø§Ù‡Ø²ÙŠÙ† ØªÙ…Ø§Ù…Ø§Ù‹.",
                "Ù…Ø§ Ù‡Ùˆ Ø§Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø°ÙŠ ØªØ®Ø´Ù‰ Ù…ÙˆØ§Ø¬Ù‡ØªÙ‡ØŸ"
            ]
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø· - Ù…Ù†Ø¸Ù…
        elif self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø·':
            if any(w in msg_lower for w in ['Ù†Ø¸Ø§Ù…', 'Ù…Ø±Ø§Ù‚Ø¨Ø©', 'Ø£Ù…Ø§Ù†', '(system|security|control)']):
                return [
                    "Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ ÙŠØ­ØªØ§Ø¬ Ù…Ø±Ø§Ø¬Ø¹Ø©. ÙˆØ¬Ø¯Øª Ø«ØºØ±Ø§Øª ÙŠØ¬Ø¨ Ø³Ø¯Ù‡Ø§ ÙÙˆØ±Ø§Ù‹.",
                    "Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„ÙˆÙ‚Ø§Ø¦ÙŠØ© Ø£ÙØ¶Ù„ Ù…Ù† Ø§Ù„Ø¹Ù„Ø§Ø¬. Ø£Ù†ØµØ­ Ø¨ØªØ¯Ù‚ÙŠÙ‚ Ø´Ù‡Ø±ÙŠ.",
                    "Ø§Ù„Ø£Ù…Ø§Ù† Ù„ÙŠØ³ ÙƒÙ„ÙØ©ØŒ Ø¨Ù„ Ø§Ø³ØªØ«Ù…Ø§Ø±."
                ]
            return [
                "Ø§Ù„Ù†Ø¸Ø§Ù… ÙŠØ­Ù…ÙŠÙ†Ø§ Ù…Ù† Ø§Ù„ÙÙˆØ¶Ù‰. Ù‡Ù„ Ø§Ù„Ù†Ø¸Ø§Ù… Ù„Ø¯ÙŠÙƒ Ø³Ù„ÙŠÙ…ØŸ",
                "Ù…Ø§ Ù‡ÙŠ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„ØªÙŠ ØªØ±ÙŠØ¯ Ù…Ø±Ø§Ø¬Ø¹ØªÙ‡Ø§ØŸ"
            ]
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù† - Ø¹Ø§Ø¯Ù„
        elif self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù†':
            if any(w in msg_lower for w in ['Ø¹Ø¯Ù„', 'ØªÙˆØ§Ø²Ù†', 'Ù†Ø²Ø§Ø¹', '(fair|balance|dispute)']):
                return [
                    "Ø§Ù„Ø¹Ø¯Ù„ ÙŠÙ‚ØªØ¶ÙŠ Ø³Ù…Ø§Ø¹ Ø§Ù„Ø·Ø±ÙÙŠÙ†. Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù‚ØµØ© Ø§Ù„ÙƒØ§Ù…Ù„Ø©ØŸ",
                    "Ø§Ù„ØªÙˆØ§Ø²Ù† Ù…Ù‡Ù…: Ù„Ø§ ØªÙØ±Ø· ÙÙŠ Ø§Ù„Ø¹Ù…Ù„ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨ Ø§Ù„ØµØ­Ø©.",
                    "Ø§Ù„Ø­Ù„ Ø§Ù„Ø¹Ø§Ø¯Ù„ ÙŠØ®Ø¯Ù… Ø§Ù„Ø¬Ù…ÙŠØ¹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¯Ù‰ Ø§Ù„Ø·ÙˆÙŠÙ„."
                ]
            return [
                "Ø§Ù„Ø§Ø¹ØªØ¯Ø§Ù„ Ù‡Ùˆ Ø§Ù„Ø³Ø¨ÙŠÙ„. ØªØ¬Ù†Ø¨ Ø§Ù„ØªØ·Ø±Ù ÙÙŠ ÙƒÙ„ Ø´ÙŠØ¡.",
                "Ù‡Ù„ Ù‡Ù†Ø§Ùƒ Ù…ÙˆØ¶ÙˆØ¹ ÙŠØ­ØªØ§Ø¬ Ù„Ù†Ø¸Ø±Ø© Ù…Ø­Ø§ÙŠØ¯Ø©ØŸ"
            ]
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ - Ù…Ø±Ù†
        elif self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ':
            if any(w in msg_lower for w in ['ØªØºÙŠÙŠØ±', 'ØªØ·ÙˆØ±', 'Ø¬Ø¯ÙŠØ¯', '(change|evolve|new)']):
                return [
                    "Ø§Ù„ØªØºÙŠÙŠØ± ÙØ±ØµØ©ØŒ Ù„ÙŠØ³ ØªÙ‡Ø¯ÙŠØ¯Ø§Ù‹. Ø¯Ø¹Ù†Ø§ Ù†ØªÙƒÙŠÙ Ù…Ø¹Ù‡.",
                    "Ù…Ù† Ù„Ø§ ÙŠØªÙƒÙŠÙ ÙŠØªØ®Ù„Ù. Ø§Ù„Ø¹Ø§Ù„Ù… ÙŠØªØºÙŠØ± Ø¨Ø³Ø±Ø¹Ø©.",
                    "Ø§Ù„Ù…Ø±ÙˆÙ†Ø© ÙÙŠ Ø§Ù„Ø®Ø·Ø© ØªØ¶Ù…Ù† Ø§Ù„Ù†Ø¬Ø§Ø­."
                ]
            return [
                "Ø§Ù„ØªÙƒÙŠÙ Ù‡Ùˆ Ø³Ø± Ø§Ù„Ø¨Ù‚Ø§Ø¡. Ù‡Ù„ Ø£Ù†Øª Ø¬Ø§Ù‡Ø² Ù„Ù„ØªØºÙŠÙŠØ±ØŸ",
                "Ø§Ù„Ø«Ø¨Ø§Øª ÙÙŠ Ø§Ù„Ù‡Ø¯ÙØŒ Ø§Ù„Ù…Ø±ÙˆÙ†Ø© ÙÙŠ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø©."
            ]
        
        # Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø© - Ø®Ø¨ÙŠØ±
        elif self.name == 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø©':
            if any(w in msg_lower for w in ['ØªØ§Ø±ÙŠØ®', 'Ø³Ø¨Ù‚', 'Ù…Ø§Ø¶ÙŠ', '(history|past|before)']):
                return [
                    "Ù…Ø±Ø±Ù†Ø§ Ø¨Ù…Ø«Ù„ Ù‡Ø°Ø§ ÙÙŠ 2019. Ø§Ù„Ø­Ù„ ÙƒØ§Ù†... Ù‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† Ø£Ø±ÙˆÙŠ Ù„Ùƒ Ø§Ù„ØªØ¬Ø±Ø¨Ø©ØŸ",
                    "Ø§Ù„ØªØ§Ø±ÙŠØ® ÙŠØ¹ÙŠØ¯ Ù†ÙØ³Ù‡. Ø¯Ø¹Ù†Ø§ Ù†ØªØ¹Ù„Ù… Ù…Ù† Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù…Ø§Ø¶ÙŠ.",
                    "Ø®Ø¨Ø±Ø© 20 Ø³Ù†Ø© ØªÙ‚ÙˆÙ„: Ø§Ù„ØµØ¨Ø± ÙŠÙÙƒØ§ÙØ£ Ø¯Ø§Ø¦Ù…Ø§Ù‹."
                ]
            return [
                "Ù„Ø¯ÙŠÙ†Ø§ Ø£Ø±Ø´ÙŠÙ ØºÙ†ÙŠ Ù…Ù† Ø§Ù„ØªØ¬Ø§Ø±Ø¨. Ø§Ø³ØªÙØ¯ Ù…Ù†Ù‡.",
                "Ù‡Ù„ ØªØ±ÙŠØ¯ Ø£Ù† Ø£Ø±ÙˆÙŠ Ù„Ùƒ Ù‚ØµØ© Ù…Ø´Ø§Ø¨Ù‡Ø© Ù…Ø±Øª Ø¹Ù„ÙŠÙ†Ø§ØŸ"
            ]
        
        # Ø¹Ø§Ù…
        return [self.personality['greeting']]


class SmartCouncil:
    """Ø§Ù„Ù…Ø¬Ù„Ø³ Ø§Ù„Ø°ÙƒÙŠ - Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø­ÙƒÙ…Ø§Ø¡ AI"""
    
    def __init__(self):
        self.wise_men: Dict[str, WiseManAI] = {}
        self.core_evidence_wise_men = {
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø©',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø·',
            'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù†',
            'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø©'
        }
        self._initialize_council()
    
    def _initialize_council(self):
        """ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ù…Ø¬Ù„Ø³ Ø¨Ù€ 16 Ø­ÙƒÙŠÙ…"""
        print("[Council] Initializing Smart Council...")
        
        # ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù€ 16 Ø­ÙƒÙŠÙ…
        wise_men_config = [
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±', 'Ø±Ø¦ÙŠØ³ Ø§Ù„Ù…Ø¬Ù„Ø³', 'Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©', 'high_council'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„', 'ØªØ®Ø·ÙŠØ· Ø·ÙˆÙŠÙ„ Ø§Ù„Ù…Ø¯Ù‰', 'Ø§Ù„Ø±Ø¤ÙŠØ©', 'seventh_dimension'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø©', 'ØªØ­Ù„ÙŠÙ„ Ø¹Ù…ÙŠÙ‚', 'Ø§Ù„ØªØ­Ù„ÙŠÙ„', 'domain_experts'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù†', 'Ø§Ù„Ø¹Ø¯Ø§Ù„Ø©', 'Ø§Ù„Ù…ÙˆØ§Ø²Ù†Ø©', 'balance'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©', 'Ø§Ù„Ù…Ø¨Ø§Ø¯Ø±Ø©', 'Ø§Ù„Ø¬Ø±Ø£Ø©', 'shadow_light'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø·', 'Ù…Ø±Ø§Ù‚Ø¨Ø©', 'Ø§Ù„Ù†Ø¸Ø§Ù…', 'guardian'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ', 'ØªØ·ÙˆØ±', 'Ø§Ù„ØªØºÙŠÙŠØ±', 'learning_core'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø©', 'ØªØ§Ø±ÙŠØ®', 'Ø§Ù„Ø®Ø¨Ø±Ø©', 'eternity'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù…', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„ØªÙ†ÙÙŠØ°', 'execution'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙ†ÙÙŠØ°', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²', 'meta_team'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ø±Ø¨Ø·', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„ØªÙˆØ§ØµÙ„', 'cosmic_bridge'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙ‚Ø§Ø±ÙŠØ±', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª', 'scouts'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙ†Ø³ÙŠÙ‚', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„ØªÙ†Ø¸ÙŠÙ…', 'meta_architect'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ù…ØªØ§Ø¨Ø¹Ø©', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©', 'president'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„Ø¬ÙˆØ¯Ø©', 'builder_council'),
            ('Ø­ÙƒÙŠÙ… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦', 'Ø¹Ù…Ù„ÙŠØ§Øª', 'Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©', 'executive_controller')
        ]
        
        for name, role, specialty, layer in wise_men_config:
            # Ø§Ø¨Ø­Ø« Ø¹Ù† checkpoint
            checkpoint_path = None
            layer_dir = CHECKPOINT_DIR / layer
            if layer_dir.exists():
                checkpoints = list(layer_dir.glob("*.pt"))
                if checkpoints:
                    checkpoint_path = checkpoints[-1]  # latest
            
            self.wise_men[name] = WiseManAI(name, role, specialty, checkpoint_path)
        
        print(f"[OK] Smart Council ready: {len(self.wise_men)} AI Wise Men")
    
    def ask(self, message: str, specific_wise_man: Optional[str] = None) -> Dict:
        """
        Ø§Ø³Ø£Ù„ Ø§Ù„Ù…Ø¬Ù„Ø³
        
        Args:
            message: Ø³Ø¤Ø§Ù„Ùƒ
            specific_wise_man: Ø­ÙƒÙŠÙ… Ù…Ø­Ø¯Ø¯ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        
        Returns:
            Ø§Ù„Ø±Ø¯ Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø­ÙƒÙŠÙ…
        """
        # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ø°Ø§ Ù…Ø§ Ø­Ø¯Ø¯Øª
        if specific_wise_man and specific_wise_man in self.wise_men:
            wise_man = self.wise_men[specific_wise_man]
        else:
            wise_man = self._select_best_wise_man(message)
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø±Ø¯ Ù…ÙˆØ«Ù‘Ù‚ Ù‚Ø¯Ø± Ø§Ù„Ø¥Ù…ÙƒØ§Ù†
        evidence_result = self._think_with_evidence_retry(wise_man, message, max_attempts=3)
        if evidence_result:
            response = evidence_result['response']
            response_source = evidence_result.get('response_source', 'training+persona')
            confidence = evidence_result.get('confidence', 0.0)
            evidence = evidence_result.get('evidence', [])
        else:
            response = (
                "Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹ Ø­Ø§Ù„ÙŠØ§Ù‹ Ø¹Ø§Ù… ÙˆÙ…Ø§ Ø¹Ù†Ø¯ÙŠ Ù„Ù‡ evidence ØªØ¯Ø±ÙŠØ¨ÙŠ ÙƒØ§ÙÙŠ. "
                "Ø­Ø¯Ø¯ Ø§Ù„Ù…Ø¬Ø§Ù„ Ø¨ÙƒÙ„Ù…Ø§Øª Ø¯Ù‚ÙŠÙ‚Ø© (Ù…Ø«Ø§Ù„: React Hooks, FastAPI auth, ERP inventory risk) "
                "Ø­ØªÙ‰ Ø£Ù‚Ø¯Ù‘Ù… Ø±Ø¯ Ù…Ø¨Ù†ÙŠ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¹Ù„Ù… ÙØ¹Ù„ÙŠØ©."
            )
            response_source = 'no-evidence-guard'
            confidence = 0.1
            evidence = []
        
        return {
            'response': response,
            'wise_man': wise_man.name,
            'role': wise_man.role,
            'specialty': wise_man.specialty,
            'personality': wise_man.personality['style'],
            'has_ai_model': wise_man.model is not None,
            'memory_size': len(wise_man.memory_store.get_conversation_history(wise_man.name, wise_man.session_id)),
            'response_source': response_source,
            'confidence': confidence,
            'evidence': evidence
        }
    
    def _select_best_wise_man(self, message: str) -> WiseManAI:
        """ÙŠØ®ØªØ§Ø± Ø£ÙØ¶Ù„ Ø­ÙƒÙŠÙ… Ù„Ù„Ø³Ø¤Ø§Ù„ Ø¨Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©"""
        msg_lower = message.lower()
        
        # Ø£ÙˆÙ„ÙˆÙŠØ© Ø¹Ø§Ù„ÙŠØ© Ù„Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…Ø­Ø¯Ø¯Ø©
        if any(w in msg_lower for w in ['ØªÙ‚Ø±ÙŠØ±', 'report', 'ØªØ­Ù„ÙŠÙ„', 'analysis', 'Ø¨ÙŠØ§Ù†Ø§Øª', 'data', 'Ø¥Ø­ØµØ§Ø¦ÙŠØ©', 'statistics']):
            # Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø© = Ø£ÙˆÙ„ÙˆÙŠØ© Ù‚ØµÙˆÙ‰ Ù„Ù„ØªØ­Ù„ÙŠÙ„
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø©' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø©']
        
        if any(w in msg_lower for w in ['Ù‚Ø±Ø§Ø±', 'decision', 'Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©', 'strategy', 'Ù†ÙØ°', 'execute']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±']
        
        if any(w in msg_lower for w in ['Ù…Ø³ØªÙ‚Ø¨Ù„', 'future', 'Ø®Ø·Ø©', 'plan', 'Ø±Ø¤ÙŠØ©', 'vision', 'ØªÙˆÙ‚Ø¹', 'forecast']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„']
        
        if any(w in msg_lower for w in ['Ø®Ø·Ø±', 'risk', 'Ø£Ø²Ù…Ø©', 'crisis', 'Ù…Ø´ÙƒÙ„Ø©', 'problem', 'Ø·ÙˆØ§Ø±Ø¦', 'emergency']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©']
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„Ø·ÙˆØ§Ø±Ø¦']
        
        if any(w in msg_lower for w in ['Ù†Ø¸Ø§Ù…', 'system', 'Ù…Ø±Ø§Ù‚Ø¨Ø©', 'monitor', 'Ø£Ù…Ø§Ù†', 'security', 'Ø¶Ø¨Ø·', 'control']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø·' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø·']
        
        if any(w in msg_lower for w in ['Ø¹Ø¯Ù„', 'justice', 'ØªÙˆØ§Ø²Ù†', 'balance', 'Ù†Ø²Ø§Ø¹', 'dispute', 'Ø­Ù‚', 'right']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù†' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù†']
        
        if any(w in msg_lower for w in ['ØªØºÙŠÙŠØ±', 'change', 'ØªØ·ÙˆØ±', 'evolve', 'ØªÙƒÙŠÙ', 'adapt', 'Ø¬Ø¯ÙŠØ¯', 'new']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ']
        
        if any(w in msg_lower for w in ['ØªØ§Ø±ÙŠØ®', 'history', 'Ù…Ø§Ø¶ÙŠ', 'past', 'Ù‚ØµØ©', 'story', 'Ø³Ø¨Ù‚', 'before']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø©' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø©']
        
        if any(w in msg_lower for w in ['ØªÙ†ÙÙŠØ°', 'implementation', 'Ø¥Ù†Ø¬Ø§Ø²', 'achievement', 'Ø¹Ù…Ù„', 'work']):
            if 'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙ†ÙÙŠØ°' in self.wise_men:
                return self.wise_men['Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙ†ÙÙŠØ°']
        
        # Ø¥Ø°Ø§ Ù…Ø§ Ù„Ù‚ÙŠÙ†Ø§ ØªØ·Ø§Ø¨Ù‚ ÙˆØ§Ø¶Ø­ØŒ Ù†Ø®ØªØ§Ø± Ø­Ø³Ø¨ Ø±Ù‚Ù… Ø§Ù„Ø£Ø­Ø±Ù
        # (Ø¹Ø´ÙˆØ§Ø¦ÙŠØ© Ù…ØªØ³Ù‚Ø© - Ù†ÙØ³ Ø§Ù„Ø³Ø¤Ø§Ù„ = Ù†ÙØ³ Ø§Ù„Ø­ÙƒÙŠÙ…)
        import hashlib
        hash_val = int(hashlib.md5(msg_lower.encode()).hexdigest(), 16)
        wise_list = [
            self.wise_men[name]
            for name in self.core_evidence_wise_men
            if name in self.wise_men
        ] or list(self.wise_men.values())
        return wise_list[hash_val % len(wise_list)]
    
    def get_all_wise_men(self) -> List[Dict]:
        """Ù‚Ø§Ø¦Ù…Ø© ÙƒÙ„ Ø§Ù„Ø­ÙƒÙ…Ø§Ø¡"""
        return [
            {
                'name': wm.name,
                'role': wm.role,
                'specialty': wm.specialty,
                'personality': wm.personality['style'],
                'has_model': wm.model is not None,
                'memory': len(wm.memory_store.get_conversation_history(wm.name, wm.session_id))
            }
            for wm in self.wise_men.values()
        ]
    
    def _think_with_evidence_retry(self, wm: WiseManAI, topic: str, max_attempts: int = 3) -> Optional[Dict]:
        prompts = [
            topic,
            f"{topic} Ù…Ø¹ Ù…Ø±Ø¬Ø¹ ØªØ¯Ø±ÙŠØ¨ÙŠ ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø«Ø§Ù„ Ø¹Ù…Ù„ÙŠ.",
            f"{topic} Ø§Ø°ÙƒØ± Ø§Ù„Ø¯Ù„ÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ÙŠ Ø§Ù„Ø°ÙŠ Ø§Ø³ØªÙ†Ø¯Øª Ø¹Ù„ÙŠÙ‡ Ø¨Ø´ÙƒÙ„ Ù…Ø¨Ø§Ø´Ø±."
        ]

        for prompt in prompts[:max_attempts]:
            resp = wm.think(prompt, strict_evidence=True)
            evidence = wm.last_generation_meta.get('evidence', [])
            if resp and evidence:
                return {
                    'wise_man': wm.name,
                    'role': wm.role,
                    'response': resp,
                    'response_source': wm.last_generation_meta.get('source', 'training+persona'),
                    'confidence': wm.last_generation_meta.get('confidence', 0.0),
                    'evidence': evidence
                }
        return None

    def discuss(self, topic: str) -> List[Dict]:
        """
        Ù†Ù‚Ø§Ø´ Ø¬Ù…Ø§Ø¹ÙŠ - ÙƒÙ„ Ø§Ù„Ø­ÙƒÙ…Ø§Ø¡ ÙŠØ´Ø§Ø±ÙƒÙˆÙ† Ø¨Ø±Ø£ÙŠÙ‡Ù…
        """
        responses = []
        candidate_names = [
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ù‚Ø±Ø§Ø±',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¨ØµÙŠØ±Ø©',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø´Ø¬Ø§Ø¹Ø©',
            'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙˆØ§Ø²Ù†',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø¶Ø¨Ø·',
            'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙƒÙŠÙ',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ø°Ø§ÙƒØ±Ø©',
            'Ø­ÙƒÙŠÙ… Ø§Ù„ØªÙ†ÙÙŠØ°',
            'Ø­ÙƒÙŠÙ… Ø§Ù„Ù†Ø¸Ø§Ù…'
        ]

        for name in candidate_names:
            wm = self.wise_men.get(name)
            if not wm:
                continue
            result = self._think_with_evidence_retry(wm, topic)
            if result:
                responses.append(result)
            if len(responses) >= 5:
                break
        
        return responses


# Global instance
smart_council = SmartCouncil()
