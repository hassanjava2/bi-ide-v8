#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    Bi IDE - Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø´Ø§Ù…Ù„ Ù„Ù„Ø°ÙƒØ§Ø¡                      â•‘
â•‘                        AI Training System v1.0                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰:                                                                â•‘
â•‘    â€¢ ÙÙ‡Ù… Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ                                                       â•‘
â•‘    â€¢ ØªØ·ÙˆÙŠØ± ÙˆØ¥ÙƒÙ…Ø§Ù„ Ø§Ù„ÙƒÙˆØ¯                                                      â•‘
â•‘    â€¢ Ø§ÙƒØªØ´Ø§Ù ÙˆØ¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡                                                   â•‘
â•‘    â€¢ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ©                                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Ø§Ù„ØªØ´ØºÙŠÙ„: python train_ai.py                                                 â•‘
â•‘  Ø£Ùˆ:      python train_ai.py --mode full                                     â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import json
import time
import argparse
import logging
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field
from collections import defaultdict

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ±Ù…ÙŠØ² Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
if sys.platform == 'win32':
    import locale
    locale.setlocale(locale.LC_ALL, '')
    sys.stdout.reconfigure(encoding='utf-8')

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ø«ÙˆØ§Ø¨Øª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"
MODELS_DIR = BASE_DIR / "models"
OUTPUT_DIR = BASE_DIR / "training" / "output"
LOGS_DIR = BASE_DIR / "training" / "logs"

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
for dir_path in [OUTPUT_DIR, LOGS_DIR]:
    dir_path.mkdir(parents=True, exist_ok=True)

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªØ³Ø¬ÙŠÙ„
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    handlers=[
        logging.FileHandler(LOGS_DIR / f"training_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log", encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù‡ÙŠØ§ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class CodeSample:
    """Ø¹ÙŠÙ†Ø© ÙƒÙˆØ¯ Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
    code: str
    language: str
    description: str = ""
    tags: List[str] = field(default_factory=list)
    metadata: Dict = field(default_factory=dict)


@dataclass 
class ErrorPattern:
    """Ù†Ù…Ø· Ø®Ø·Ø£ Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø¹Ù„Ù‰ Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
    error_code: str
    correct_code: str
    error_type: str
    language: str
    description: str = ""
    explanation: str = ""


@dataclass
class QAPair:
    """Ø²ÙˆØ¬ Ø³Ø¤Ø§Ù„ ÙˆØ¬ÙˆØ§Ø¨ Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
    question: str
    answer: str
    context: str = ""
    category: str = ""


@dataclass
class TrainingStats:
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
    total_samples: int = 0
    code_samples: int = 0
    error_patterns: int = 0
    qa_pairs: int = 0
    languages: Dict[str, int] = field(default_factory=dict)
    categories: Dict[str, int] = field(default_factory=dict)
    start_time: float = 0
    end_time: float = 0
    
    @property
    def duration(self) -> float:
        return self.end_time - self.start_time if self.end_time else 0


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù…Ø­Ù…Ù‘Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DataLoader:
    """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹"""
    
    def __init__(self, data_dir: Path):
        self.data_dir = data_dir
        self.code_samples: List[CodeSample] = []
        self.error_patterns: List[ErrorPattern] = []
        self.qa_pairs: List[QAPair] = []
        self.knowledge_base: Dict[str, Any] = {}
        
    def load_all(self) -> Dict[str, Any]:
        """ØªØ­Ù…ÙŠÙ„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        logger.info("=" * 60)
        logger.info("Loading Training Data...")
        logger.info("=" * 60)
        
        # ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ù…Ø¹Ø±ÙØ©
        self._load_knowledge_bases()
        
        # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªØ®ØµØµØ©
        self._load_training_data()
        
        # ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª
        self._load_conversation_data()
        
        # ØªØ­Ù…ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        self._load_error_patterns()
        
        stats = {
            "code_samples": len(self.code_samples),
            "error_patterns": len(self.error_patterns),
            "qa_pairs": len(self.qa_pairs),
            "knowledge_topics": len(self.knowledge_base)
        }
        
        logger.info(f"[OK] Data loaded: {stats}")
        return stats
    
    def _load_knowledge_bases(self):
        """ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©"""
        knowledge_files = [
            "comprehensive-knowledge-base.js",
            "extended-knowledge-base.js",
            "programming-knowledge.js",
            "computer-science-knowledge.js",
            "frameworks-knowledge.js"
        ]
        
        for filename in knowledge_files:
            filepath = self.data_dir / filename
            if filepath.exists():
                try:
                    content = filepath.read_text(encoding='utf-8')
                    data = self._parse_js_module(content)
                    if data:
                        self.knowledge_base.update(data)
                        logger.info(f"   âœ“ {filename}")
                except Exception as e:
                    logger.warning(f"   [WARN] Error in {filename}: {e}")
    
    def _load_training_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…ØªØ®ØµØµØ©"""
        training_files = [
            ("advanced-debugging-training.js", "debugging"),
            ("design-patterns-training.js", "patterns"),
            ("security-vulnerabilities-training.js", "security"),
            ("ai-ml-programming-training.js", "ai_ml"),
            ("advanced-algorithms-data-structures.js", "algorithms")
        ]
        
        for filename, category in training_files:
            filepath = self.data_dir / filename
            if filepath.exists():
                try:
                    content = filepath.read_text(encoding='utf-8')
                    samples = self._extract_code_samples(content, category)
                    self.code_samples.extend(samples)
                    logger.info(f"   âœ“ {filename}: {len(samples)} Ø¹ÙŠÙ†Ø©")
                except Exception as e:
                    logger.warning(f"   [WARN] Error in {filename}: {e}")
    
    def _load_conversation_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª"""
        conv_files = [
            "advanced-conversation-data.json",
            "ai-conversations.json",
            "conversation-training.js",
            "smart-replies-training.js"
        ]
        
        for filename in conv_files:
            filepath = self.data_dir / filename
            if filepath.exists():
                try:
                    if filename.endswith('.json'):
                        data = json.loads(filepath.read_text(encoding='utf-8'))
                        pairs = self._extract_qa_from_json(data)
                    else:
                        content = filepath.read_text(encoding='utf-8')
                        pairs = self._extract_qa_from_js(content)
                    
                    self.qa_pairs.extend(pairs)
                    logger.info(f"   âœ“ {filename}: {len(pairs)} Ù…Ø­Ø§Ø¯Ø«Ø©")
                except Exception as e:
                    logger.warning(f"   [WARN] Error in {filename}: {e}")
    
    def _load_error_patterns(self):
        """ØªØ­Ù…ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        error_files = [
            "advanced-error-detection.js",
            "debugging-mastery-training.js"
        ]
        
        for filename in error_files:
            filepath = self.data_dir / filename
            if filepath.exists():
                try:
                    content = filepath.read_text(encoding='utf-8')
                    patterns = self._extract_error_patterns(content)
                    self.error_patterns.extend(patterns)
                    logger.info(f"   âœ“ {filename}: {len(patterns)} Ù†Ù…Ø· Ø®Ø·Ø£")
                except Exception as e:
                    logger.warning(f"   [WARN] Error in {filename}: {e}")
    
    def _parse_js_module(self, content: str) -> Dict:
        """ØªØ­Ù„ÙŠÙ„ Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù JavaScript ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        import re
        
        data = {}
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ØµÙÙˆÙØ§Øª ÙˆØ§Ù„ÙƒØ§Ø¦Ù†Ø§Øª
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† patterns Ù…Ø«Ù„: const name = { ... } Ø£Ùˆ const name = [ ... ]
        pattern = r'(?:const|let|var)\s+(\w+)\s*=\s*(\{[\s\S]*?\}|\[[\s\S]*?\]);'
        
        matches = re.findall(pattern, content)
        for name, value in matches:
            try:
                # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ JavaScript Ø¥Ù„Ù‰ JSON
                json_str = self._js_to_json(value)
                data[name] = json.loads(json_str)
            except:
                pass
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†ØµÙˆØµ ÙˆØ§Ù„Ø£Ù…Ø«Ù„Ø©
        code_blocks = re.findall(r'```(\w+)?\n([\s\S]*?)```', content)
        if code_blocks:
            data['code_examples'] = [
                {'language': lang or 'text', 'code': code}
                for lang, code in code_blocks
            ]
        
        return data
    
    def _js_to_json(self, js_str: str) -> str:
        """ØªØ­ÙˆÙŠÙ„ JavaScript object Ø¥Ù„Ù‰ JSON ØµØ§Ù„Ø­"""
        import re
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª
        result = re.sub(r'//.*$', '', js_str, flags=re.MULTILINE)
        result = re.sub(r'/\*[\s\S]*?\*/', '', result)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø¨Ø¯ÙˆÙ† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù‚ØªØ¨Ø§Ø³
        result = re.sub(r'(\w+):', r'"\1":', result)
        
        # ØªØ­ÙˆÙŠÙ„ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„Ø§Ù‚ØªØ¨Ø§Ø³ Ø§Ù„Ù…ÙØ±Ø¯Ø©
        result = result.replace("'", '"')
        
        # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ÙÙˆØ§ØµÙ„ Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
        result = re.sub(r',\s*([}\]])', r'\1', result)
        
        return result
    
    def _extract_code_samples(self, content: str, category: str) -> List[CodeSample]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¹ÙŠÙ†Ø§Øª Ø§Ù„ÙƒÙˆØ¯ Ù…Ù† Ø§Ù„Ù…Ø­ØªÙˆÙ‰"""
        import re
        
        samples = []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† code blocks
        code_pattern = r'(?:code|example|snippet)[\'":\s]*[`\'"]*([\s\S]*?)[`\'"]*(?:,|\})'
        
        for match in re.finditer(code_pattern, content, re.IGNORECASE):
            code = match.group(1).strip()
            if len(code) > 20:  # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø£Ù…Ø«Ù„Ø© Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                language = self._detect_language(code)
                samples.append(CodeSample(
                    code=code,
                    language=language,
                    tags=[category],
                    metadata={'source': 'training_file'}
                ))
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† code blocks Ø¨Ù€ backticks
        backtick_pattern = r'```(\w+)?\n([\s\S]*?)```'
        for match in re.finditer(backtick_pattern, content):
            lang = match.group(1) or 'javascript'
            code = match.group(2).strip()
            if len(code) > 20:
                samples.append(CodeSample(
                    code=code,
                    language=lang,
                    tags=[category],
                    metadata={'source': 'training_file'}
                ))
        
        return samples
    
    def _extract_qa_from_json(self, data: Any) -> List[QAPair]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø²ÙˆØ§Ø¬ Q&A Ù…Ù† JSON"""
        pairs = []
        
        def extract_recursive(obj, path=""):
            if isinstance(obj, dict):
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Q&A
                q = obj.get('question') or obj.get('q') or obj.get('input')
                a = obj.get('answer') or obj.get('a') or obj.get('output') or obj.get('response')
                
                if q and a:
                    pairs.append(QAPair(
                        question=str(q),
                        answer=str(a),
                        category=obj.get('category', path)
                    ))
                
                for key, value in obj.items():
                    extract_recursive(value, f"{path}/{key}")
                    
            elif isinstance(obj, list):
                for i, item in enumerate(obj):
                    extract_recursive(item, path)
        
        extract_recursive(data)
        return pairs
    
    def _extract_qa_from_js(self, content: str) -> List[QAPair]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ø²ÙˆØ§Ø¬ Q&A Ù…Ù† Ù…Ù„Ù JavaScript"""
        import re
        
        pairs = []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø³Ø¤Ø§Ù„ ÙˆØ§Ù„Ø¬ÙˆØ§Ø¨
        patterns = [
            r'(?:question|q)[\'":\s]+[\'"]([^"\']+)[\'"][\s\S]*?(?:answer|a|response)[\'":\s]+[\'"]([^"\']+)[\'"]',
            r'(?:input)[\'":\s]+[\'"]([^"\']+)[\'"][\s\S]*?(?:output)[\'":\s]+[\'"]([^"\']+)[\'"]'
        ]
        
        for pattern in patterns:
            for match in re.finditer(pattern, content, re.IGNORECASE):
                pairs.append(QAPair(
                    question=match.group(1).strip(),
                    answer=match.group(2).strip()
                ))
        
        return pairs
    
    def _extract_error_patterns(self, content: str) -> List[ErrorPattern]:
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
        import re
        
        patterns = []
        
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø®Ø·Ø£ ÙˆØ§Ù„Ø¥ØµÙ„Ø§Ø­
        error_pattern = r'(?:wrong|error|incorrect|bug)[\'":\s]*[\'"`]*([\s\S]*?)[\'"`]*[\s\S]*?(?:correct|fix|solution)[\'":\s]*[\'"`]*([\s\S]*?)[\'"`]*(?:,|\})'
        
        for match in re.finditer(error_pattern, content, re.IGNORECASE):
            error_code = match.group(1).strip()
            correct_code = match.group(2).strip()
            
            if len(error_code) > 10 and len(correct_code) > 10:
                patterns.append(ErrorPattern(
                    error_code=error_code,
                    correct_code=correct_code,
                    error_type='general',
                    language=self._detect_language(error_code)
                ))
        
        return patterns
    
    def _detect_language(self, code: str) -> str:
        """Ø§ÙƒØªØ´Ø§Ù Ù„ØºØ© Ø§Ù„Ø¨Ø±Ù…Ø¬Ø©"""
        indicators = {
            'javascript': ['function', 'const ', 'let ', 'var ', '=>', 'require(', 'import '],
            'python': ['def ', 'import ', 'from ', 'class ', 'self.', '__init__', 'print('],
            'java': ['public class', 'private ', 'void ', 'String ', 'System.out'],
            'cpp': ['#include', 'std::', 'cout', 'int main', '::'],
            'html': ['<html', '<div', '<span', '</div>', '<!DOCTYPE'],
            'css': ['{', '}', 'color:', 'font-', 'margin:', 'padding:'],
            'sql': ['SELECT', 'FROM', 'WHERE', 'INSERT', 'UPDATE', 'CREATE TABLE'],
            'php': ['<?php', '$_', 'echo ', '->'],
            'rust': ['fn ', 'let mut', 'impl ', '::new('],
            'go': ['func ', 'package ', 'import (', 'fmt.']
        }
        
        code_lower = code.lower()
        scores = defaultdict(int)
        
        for lang, keywords in indicators.items():
            for keyword in keywords:
                if keyword.lower() in code_lower:
                    scores[lang] += 1
        
        if scores:
            return max(scores, key=scores.get)
        return 'unknown'


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù…ÙˆÙ„Ù‘Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TrainingDataGenerator:
    """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ø¥Ø¶Ø§ÙÙŠØ©"""
    
    def __init__(self):
        self.templates = self._load_templates()
    
    def _load_templates(self) -> Dict:
        """ØªØ­Ù…ÙŠÙ„ Ù‚ÙˆØ§Ù„Ø¨ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        return {
            'error_fixes': {
                'javascript': [
                    {
                        'error': 'console.log(undefined_variable)',
                        'fix': 'const defined_variable = "value";\nconsole.log(defined_variable)',
                        'type': 'ReferenceError',
                        'explanation': 'ÙŠØ¬Ø¨ ØªØ¹Ø±ÙŠÙ Ø§Ù„Ù…ØªØºÙŠØ± Ù‚Ø¨Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡'
                    },
                    {
                        'error': 'const arr = [1,2,3];\narr.map(x => x.toUpperCase())',
                        'fix': 'const arr = ["a","b","c"];\narr.map(x => x.toUpperCase())',
                        'type': 'TypeError',
                        'explanation': 'toUpperCase() ØªØ¹Ù…Ù„ ÙÙ‚Ø· Ù…Ø¹ Ø§Ù„Ù†ØµÙˆØµ'
                    },
                    {
                        'error': 'async function getData() {\n  const data = fetch(url);\n  return data.json();\n}',
                        'fix': 'async function getData() {\n  const data = await fetch(url);\n  return await data.json();\n}',
                        'type': 'Missing await',
                        'explanation': 'ÙŠØ¬Ø¨ Ø§Ø³ØªØ®Ø¯Ø§Ù… await Ù…Ø¹ Ø§Ù„Ø¯ÙˆØ§Ù„ ØºÙŠØ± Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©'
                    },
                    {
                        'error': 'for (var i = 0; i < 5; i++) {\n  setTimeout(() => console.log(i), 100);\n}',
                        'fix': 'for (let i = 0; i < 5; i++) {\n  setTimeout(() => console.log(i), 100);\n}',
                        'type': 'Closure issue',
                        'explanation': 'Ø§Ø³ØªØ®Ø¯Ù… let Ø¨Ø¯Ù„ var ÙÙŠ Ø§Ù„Ø­Ù„Ù‚Ø§Øª Ù…Ø¹ closures'
                    },
                    {
                        'error': 'const obj = {a: 1};\nconst copy = obj;\ncopy.a = 2; // obj.a Ø£ÙŠØ¶Ø§Ù‹ ØªØªØºÙŠØ±',
                        'fix': 'const obj = {a: 1};\nconst copy = {...obj};\ncopy.a = 2; // obj.a ØªØ¨Ù‚Ù‰ 1',
                        'type': 'Reference mutation',
                        'explanation': 'Ø§Ø³ØªØ®Ø¯Ù… spread operator Ù„Ù†Ø³Ø® Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª'
                    }
                ],
                'python': [
                    {
                        'error': 'def add(a, b=[]):\n    b.append(a)\n    return b',
                        'fix': 'def add(a, b=None):\n    if b is None:\n        b = []\n    b.append(a)\n    return b',
                        'type': 'Mutable default argument',
                        'explanation': 'Ù„Ø§ ØªØ³ØªØ®Ø¯Ù… ÙƒØ§Ø¦Ù†Ø§Øª Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØºÙŠÙŠØ± ÙƒÙ‚ÙŠÙ… Ø§ÙØªØ±Ø§Ø¶ÙŠØ©'
                    },
                    {
                        'error': 'items = [1, 2, 3]\nfor i in items:\n    if i == 2:\n        items.remove(i)',
                        'fix': 'items = [1, 2, 3]\nitems = [i for i in items if i != 2]',
                        'type': 'Modifying list while iterating',
                        'explanation': 'Ù„Ø§ ØªØ¹Ø¯Ù„ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¹Ù„ÙŠÙ‡Ø§'
                    },
                    {
                        'error': 'class MyClass:\n    items = []\n    def add(self, item):\n        self.items.append(item)',
                        'fix': 'class MyClass:\n    def __init__(self):\n        self.items = []\n    def add(self, item):\n        self.items.append(item)',
                        'type': 'Class variable mutation',
                        'explanation': 'Ø§Ø³ØªØ®Ø¯Ù… instance variables Ø¨Ø¯Ù„ class variables Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªØºÙŠØ±Ø©'
                    }
                ]
            },
            'code_patterns': {
                'javascript': [
                    {
                        'name': 'Singleton Pattern',
                        'code': '''class Database {
    static instance = null;
    
    static getInstance() {
        if (!Database.instance) {
            Database.instance = new Database();
        }
        return Database.instance;
    }
    
    constructor() {
        if (Database.instance) {
            return Database.instance;
        }
        this.connection = null;
    }
}''',
                        'description': 'Ù†Ù…Ø· Singleton ÙŠØ¶Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù†Ø³Ø®Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø· Ù…Ù† Ø§Ù„ÙƒÙ„Ø§Ø³'
                    },
                    {
                        'name': 'Observer Pattern',
                        'code': '''class EventEmitter {
    constructor() {
        this.events = {};
    }
    
    on(event, callback) {
        if (!this.events[event]) {
            this.events[event] = [];
        }
        this.events[event].push(callback);
    }
    
    emit(event, data) {
        if (this.events[event]) {
            this.events[event].forEach(cb => cb(data));
        }
    }
    
    off(event, callback) {
        if (this.events[event]) {
            this.events[event] = this.events[event]
                .filter(cb => cb !== callback);
        }
    }
}''',
                        'description': 'Ù†Ù…Ø· Observer Ù„Ù„Ø§Ø´ØªØ±Ø§Ùƒ ÙÙŠ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« ÙˆØ§Ù„Ø¥Ø´Ø¹Ø§Ø±Ø§Øª'
                    },
                    {
                        'name': 'Factory Pattern',
                        'code': '''class ShapeFactory {
    static create(type, options) {
        switch(type) {
            case 'circle':
                return new Circle(options.radius);
            case 'rectangle':
                return new Rectangle(options.width, options.height);
            case 'triangle':
                return new Triangle(options.base, options.height);
            default:
                throw new Error(`Unknown shape: ${type}`);
        }
    }
}

// Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
const circle = ShapeFactory.create('circle', { radius: 5 });
const rect = ShapeFactory.create('rectangle', { width: 10, height: 5 });''',
                        'description': 'Ù†Ù…Ø· Factory Ù„Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒØ§Ø¦Ù†Ø§Øª Ø¨Ø´ÙƒÙ„ Ù…Ø±ÙƒØ²ÙŠ'
                    }
                ],
                'python': [
                    {
                        'name': 'Decorator Pattern',
                        'code': '''from functools import wraps
import time

def timing_decorator(func):
    @wraps(func)
    def wrapper(*args, **kwargs):
        start = time.time()
        result = func(*args, **kwargs)
        end = time.time()
        print(f"{func.__name__} took {end-start:.4f}s")
        return result
    return wrapper

def retry_decorator(max_retries=3, delay=1):
    def decorator(func):
        @wraps(func)
        def wrapper(*args, **kwargs):
            for attempt in range(max_retries):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    if attempt < max_retries - 1:
                        time.sleep(delay)
                    else:
                        raise e
        return wrapper
    return decorator

@timing_decorator
@retry_decorator(max_retries=3)
def fetch_data(url):
    # Ø¬Ù„Ø¨ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    pass''',
                        'description': 'Ù†Ù…Ø· Decorator Ù„Ø¥Ø¶Ø§ÙØ© ÙˆØ¸Ø§Ø¦Ù Ù„Ù„Ø¯ÙˆØ§Ù„'
                    },
                    {
                        'name': 'Context Manager',
                        'code': '''from contextlib import contextmanager

class DatabaseConnection:
    def __init__(self, connection_string):
        self.conn_str = connection_string
        self.connection = None
    
    def __enter__(self):
        self.connection = self._connect()
        return self.connection
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.connection:
            self.connection.close()
        return False  # Ù„Ø§ ØªÙ…Ù†Ø¹ Ø§Ù„Ø§Ø³ØªØ«Ù†Ø§Ø¡Ø§Øª
    
    def _connect(self):
        # Ù…Ù†Ø·Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„
        pass

# Ø£Ùˆ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… decorator
@contextmanager
def open_file(filename, mode='r'):
    f = open(filename, mode)
    try:
        yield f
    finally:
        f.close()

# Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…
with DatabaseConnection("...") as conn:
    conn.execute("SELECT * FROM users")''',
                        'description': 'Ù†Ù…Ø· Context Manager Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…ÙˆØ§Ø±Ø¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹'
                    }
                ]
            },
            'qa_templates': [
                {
                    'q': 'Ù…Ø§ Ù‡Ùˆ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† == Ùˆ === ÙÙŠ JavaScriptØŸ',
                    'a': '== ÙŠÙ‚Ø§Ø±Ù† Ø§Ù„Ù‚ÙŠÙ… Ù…Ø¹ ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ (type coercion)ØŒ Ø¨ÙŠÙ†Ù…Ø§ === ÙŠÙ‚Ø§Ø±Ù† Ø§Ù„Ù‚ÙŠÙ… ÙˆØ§Ù„Ø£Ù†ÙˆØ§Ø¹ Ù…Ø¹Ø§Ù‹ (strict equality). Ù…Ø«Ø§Ù„: "5" == 5 ÙŠØ¹Ø·ÙŠ trueØŒ Ù„ÙƒÙ† "5" === 5 ÙŠØ¹Ø·ÙŠ false.',
                    'category': 'javascript'
                },
                {
                    'q': 'Ù…Ø§ Ù‡Ùˆ closure ÙÙŠ JavaScriptØŸ',
                    'a': 'Closure Ù‡Ùˆ Ø¯Ø§Ù„Ø© ØªØªØ°ÙƒØ± Ø§Ù„Ù…ØªØºÙŠØ±Ø§Øª Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠ (lexical scope) Ø­ØªÙ‰ Ø¨Ø¹Ø¯ Ø§Ù†ØªÙ‡Ø§Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø© Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ©. ÙŠØ³ØªØ®Ø¯Ù… Ù„Ø¥Ù†Ø´Ø§Ø¡ Ù…ØªØºÙŠØ±Ø§Øª Ø®Ø§ØµØ© ÙˆÙ„Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„Ø­Ø§Ù„Ø©.',
                    'category': 'javascript'
                },
                {
                    'q': 'Ù…Ø§ Ø§Ù„ÙØ±Ù‚ Ø¨ÙŠÙ† list Ùˆ tuple ÙÙŠ PythonØŸ',
                    'a': 'List Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ (mutable) Ø¨ÙŠÙ†Ù…Ø§ tuple ØºÙŠØ± Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ¹Ø¯ÙŠÙ„ (immutable). tuple Ø£Ø³Ø±Ø¹ ÙˆØªØ³ØªÙ‡Ù„Ùƒ Ø°Ø§ÙƒØ±Ø© Ø£Ù‚Ù„ØŒ ÙˆØªØ³ØªØ®Ø¯Ù… ÙƒÙ…ÙØ§ØªÙŠØ­ ÙÙŠ Ø§Ù„Ù‚ÙˆØ§Ù…ÙŠØ³.',
                    'category': 'python'
                },
                {
                    'q': 'ÙƒÙŠÙ Ø£ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙÙŠ async/awaitØŸ',
                    'a': 'Ø§Ø³ØªØ®Ø¯Ù… try/catch Ø­ÙˆÙ„ await Ù„Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡. Ù…Ø«Ø§Ù„:\ntry {\n  const data = await fetchData();\n} catch (error) {\n  console.error("Failed:", error);\n}',
                    'category': 'javascript'
                },
                {
                    'q': 'Ù…Ø§ Ù‡Ùˆ virtual environment ÙÙŠ Python ÙˆÙ„Ù…Ø§Ø°Ø§ Ù†Ø³ØªØ®Ø¯Ù…Ù‡ØŸ',
                    'a': 'Virtual environment Ù‡Ùˆ Ø¨ÙŠØ¦Ø© Ù…Ø¹Ø²ÙˆÙ„Ø© Ù„Ù…Ø´Ø±ÙˆØ¹ Python Ù…Ø­Ø¯Ø¯. ÙŠØ³Ù…Ø­ Ø¨ØªØ«Ø¨ÙŠØª Ù…ÙƒØªØ¨Ø§Øª Ù…Ø®ØªÙ„ÙØ© Ù„ÙƒÙ„ Ù…Ø´Ø±ÙˆØ¹ Ø¯ÙˆÙ† ØªØ¹Ø§Ø±Ø¶. Ø¥Ù†Ø´Ø§Ø¤Ù‡: python -m venv venv Ø«Ù… ØªÙØ¹ÙŠÙ„Ù‡.',
                    'category': 'python'
                },
                {
                    'q': 'ÙƒÙŠÙ Ø£Ø­Ø³Ù‘Ù† Ø£Ø¯Ø§Ø¡ React componentØŸ',
                    'a': 'Ø§Ø³ØªØ®Ø¯Ù…: 1) React.memo Ù„Ù…Ù†Ø¹ Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø±Ø³Ù… ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ© 2) useMemo Ù„Ø­ÙØ¸ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª Ø§Ù„Ù…ÙƒÙ„ÙØ© 3) useCallback Ù„Ø­ÙØ¸ Ø§Ù„Ø¯ÙˆØ§Ù„ 4) ØªÙ‚Ø³ÙŠÙ… Ø§Ù„ÙƒÙˆØ¯ (code splitting) 5) ØªØ­Ù…ÙŠÙ„ ÙƒØ³ÙˆÙ„ (lazy loading)',
                    'category': 'react'
                },
                {
                    'q': 'Ù…Ø§ Ù‡Ùˆ REST API ÙˆÙ…Ø§ Ù‡ÙŠ Ù…Ø¨Ø§Ø¯Ø¦Ù‡ØŸ',
                    'a': 'REST (Representational State Transfer) Ù‡Ùˆ Ù†Ù…Ø· Ù…Ø¹Ù…Ø§Ø±ÙŠ Ù„Ù„Ù€ APIs. Ù…Ø¨Ø§Ø¯Ø¦Ù‡: 1) Client-Server 2) Stateless 3) Cacheable 4) Uniform Interface 5) Layered System. ÙŠØ³ØªØ®Ø¯Ù… HTTP methods: GET, POST, PUT, DELETE.',
                    'category': 'api'
                },
                {
                    'q': 'ÙƒÙŠÙ Ø£Ù…Ù†Ø¹ SQL InjectionØŸ',
                    'a': 'Ø§Ø³ØªØ®Ø¯Ù…: 1) Parameterized queries / Prepared statements 2) ORM Ø¨Ø¯Ù„ SQL Ø§Ù„Ù…Ø¨Ø§Ø´Ø± 3) Input validation Ùˆ sanitization 4) Ù…Ø¨Ø¯Ø£ least privilege Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª.',
                    'category': 'security'
                }
            ]
        }
        
    def generate_error_patterns(self) -> List[ErrorPattern]:
        """ØªÙˆÙ„ÙŠØ¯ Ø£Ù†Ù…Ø§Ø· Ø£Ø®Ø·Ø§Ø¡ Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        patterns = []
        
        for lang, errors in self.templates['error_fixes'].items():
            for error_data in errors:
                patterns.append(ErrorPattern(
                    error_code=error_data['error'],
                    correct_code=error_data['fix'],
                    error_type=error_data['type'],
                    language=lang,
                    explanation=error_data['explanation']
                ))
        
        return patterns
    
    def generate_code_samples(self) -> List[CodeSample]:
        """ØªÙˆÙ„ÙŠØ¯ Ø¹ÙŠÙ†Ø§Øª ÙƒÙˆØ¯ Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        samples = []
        
        for lang, patterns_list in self.templates['code_patterns'].items():
            for pattern in patterns_list:
                samples.append(CodeSample(
                    code=pattern['code'],
                    language=lang,
                    description=pattern['description'],
                    tags=['design_pattern', pattern['name'].lower().replace(' ', '_')]
                ))
        
        return samples
    
    def generate_qa_pairs(self) -> List[QAPair]:
        """ØªÙˆÙ„ÙŠØ¯ Ø£Ø²ÙˆØ§Ø¬ Q&A Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        pairs = []
        
        for qa in self.templates['qa_templates']:
            pairs.append(QAPair(
                question=qa['q'],
                answer=qa['a'],
                category=qa.get('category', 'general')
            ))
        
        return pairs


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AITrainer:
    """Ø§Ù„Ù…Ø¯Ø±Ø¨ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ"""
    
    def __init__(self, config: Dict = None):
        self.config = config or {}
        self.data_loader = DataLoader(DATA_DIR)
        self.data_generator = TrainingDataGenerator()
        self.stats = TrainingStats()
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©
        self.training_data = {
            'code_understanding': [],      # ÙÙ‡Ù… Ø§Ù„ÙƒÙˆØ¯
            'code_completion': [],         # Ø¥ÙƒÙ…Ø§Ù„ Ø§Ù„ÙƒÙˆØ¯
            'error_detection': [],         # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            'error_fixing': [],            # Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
            'code_explanation': [],        # Ø´Ø±Ø­ Ø§Ù„ÙƒÙˆØ¯
            'qa_pairs': [],                # Ø£Ø³Ø¦Ù„Ø© ÙˆØ£Ø¬ÙˆØ¨Ø©
            'design_patterns': [],         # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØµÙ…ÙŠÙ…
            'best_practices': []           # Ø£ÙØ¶Ù„ Ø§Ù„Ù…Ù…Ø§Ø±Ø³Ø§Øª
        }
        
        # Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ (Ø³ÙŠØªÙ… ØªØ­Ù…ÙŠÙ„Ù‡ Ù„Ø§Ø­Ù‚Ø§Ù‹)
        self.model = None
        self.tokenizer = None
    
    def prepare_data(self):
        """ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨"""
        logger.info("\n" + "=" * 60)
        logger.info("Preparing Training Data")
        logger.info("=" * 60 + "\n")
        
        self.stats.start_time = time.time()
        
        # 1. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
        logger.info("1ï¸âƒ£ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø´Ø±ÙˆØ¹...")
        file_stats = self.data_loader.load_all()
        
        # 2. ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ø¶Ø§ÙÙŠØ©
        logger.info("\n2ï¸âƒ£ ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ø¥Ø¶Ø§ÙÙŠØ©...")
        generated_errors = self.data_generator.generate_error_patterns()
        generated_code = self.data_generator.generate_code_samples()
        generated_qa = self.data_generator.generate_qa_pairs()
        
        logger.info(f"   âœ“ Ø£Ù†Ù…Ø§Ø· Ø£Ø®Ø·Ø§Ø¡: {len(generated_errors)}")
        logger.info(f"   âœ“ Ø¹ÙŠÙ†Ø§Øª ÙƒÙˆØ¯: {len(generated_code)}")
        logger.info(f"   âœ“ Ø£Ø³Ø¦Ù„Ø© ÙˆØ£Ø¬ÙˆØ¨Ø©: {len(generated_qa)}")
        
        # 3. Ø¯Ù…Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        logger.info("\n3ï¸âƒ£ Ø¯Ù…Ø¬ ÙˆØªÙ†Ø¸ÙŠÙ… Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        # Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ‡Ù… Ø§Ù„ÙƒÙˆØ¯
        all_code_samples = self.data_loader.code_samples + generated_code
        self.training_data['code_understanding'] = [
            {
                'input': f"Ø§Ø´Ø±Ø­ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯:\n```{s.language}\n{s.code}\n```",
                'output': s.description or f"ÙƒÙˆØ¯ {s.language} ÙŠÙ‚ÙˆÙ… Ø¨Ù€...",
                'language': s.language
            }
            for s in all_code_samples if s.description
        ]
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        all_errors = self.data_loader.error_patterns + generated_errors
        self.training_data['error_fixing'] = [
            {
                'input': f"Ø£ØµÙ„Ø­ Ù‡Ø°Ø§ Ø§Ù„Ø®Ø·Ø£:\n```{e.language}\n{e.error_code}\n```",
                'output': f"Ø§Ù„Ø¥ØµÙ„Ø§Ø­:\n```{e.language}\n{e.correct_code}\n```\n\nØ§Ù„Ø´Ø±Ø­: {e.explanation}",
                'error_type': e.error_type,
                'language': e.language
            }
            for e in all_errors
        ]
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡
        self.training_data['error_detection'] = [
            {
                'input': f"Ù‡Ù„ ÙŠÙˆØ¬Ø¯ Ø®Ø·Ø£ ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯ØŸ\n```{e.language}\n{e.error_code}\n```",
                'output': f"Ù†Ø¹Ù…ØŒ ÙŠÙˆØ¬Ø¯ Ø®Ø·Ø£ Ù…Ù† Ù†ÙˆØ¹ {e.error_type}. {e.explanation}",
                'language': e.language
            }
            for e in all_errors
        ]
        
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø³Ø¦Ù„Ø© ÙˆØ§Ù„Ø£Ø¬ÙˆØ¨Ø©
        all_qa = self.data_loader.qa_pairs + generated_qa
        self.training_data['qa_pairs'] = [
            {
                'input': qa.question,
                'output': qa.answer,
                'category': qa.category
            }
            for qa in all_qa
        ]
        
        # Ø£Ù†Ù…Ø§Ø· Ø§Ù„ØªØµÙ…ÙŠÙ…
        self.training_data['design_patterns'] = [
            {
                'input': f"Ø§ÙƒØªØ¨ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ {s.tags[-1].replace('_', ' ')} Ø¨Ù€ {s.language}",
                'output': f"```{s.language}\n{s.code}\n```\n\n{s.description}",
                'pattern': s.tags[-1] if s.tags else 'unknown'
            }
            for s in generated_code if 'design_pattern' in s.tags
        ]
        
        # 4. Ø­Ø³Ø§Ø¨ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self._calculate_stats()
        
        logger.info("\n[OK] Data preparation completed!")
        self._print_stats()
    
    def _calculate_stats(self):
        """Ø­Ø³Ø§Ø¨ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        self.stats.code_samples = len(self.training_data['code_understanding'])
        self.stats.error_patterns = len(self.training_data['error_fixing'])
        self.stats.qa_pairs = len(self.training_data['qa_pairs'])
        
        self.stats.total_samples = sum(
            len(data) for data in self.training_data.values()
        )
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„Ù„ØºØ§Øª
        for category in ['code_understanding', 'error_fixing', 'error_detection']:
            for item in self.training_data[category]:
                lang = item.get('language', 'unknown')
                self.stats.languages[lang] = self.stats.languages.get(lang, 0) + 1
        
        # Ø­Ø³Ø§Ø¨ Ø§Ù„ÙØ¦Ø§Øª
        for item in self.training_data['qa_pairs']:
            cat = item.get('category', 'general')
            self.stats.categories[cat] = self.stats.categories.get(cat, 0) + 1
    
    def _print_stats(self):
        """Ø·Ø¨Ø§Ø¹Ø© Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        logger.info("\n" + "-" * 50)
        logger.info("Training Data Statistics:")
        logger.info("-" * 50)
        logger.info(f"   Total Samples: {self.stats.total_samples}")
        logger.info(f"   Code Samples: {self.stats.code_samples}")
        logger.info(f"   Error Patterns: {self.stats.error_patterns}")
        logger.info(f"   QA Pairs: {self.stats.qa_pairs}")
        
        if self.stats.languages:
            logger.info("\n   Languages:")
            for lang, count in sorted(self.stats.languages.items(), key=lambda x: -x[1])[:5]:
                logger.info(f"      - {lang}: {count}")
        
        if self.stats.categories:
            logger.info("\n   Categories:")
            for cat, count in sorted(self.stats.categories.items(), key=lambda x: -x[1])[:5]:
                logger.info(f"      - {cat}: {count}")
        
        logger.info("-" * 50)
    
    def save_training_data(self, output_path: Path = None):
        """Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        output_path = output_path or OUTPUT_DIR / "training_data.json"
        
        logger.info(f"\nSaving training data: {output_path}")
        
        output_data = {
            'metadata': {
                'created_at': datetime.now().isoformat(),
                'total_samples': self.stats.total_samples,
                'stats': {
                    'code_samples': self.stats.code_samples,
                    'error_patterns': self.stats.error_patterns,
                    'qa_pairs': self.stats.qa_pairs
                }
            },
            'data': self.training_data
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        
        logger.info(f"   [OK] Saved: {output_path.stat().st_size / 1024:.1f} KB")
    
    def train(self, mode: str = 'prepare'):
        """Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        logger.info("\n" + "=" * 60)
        logger.info("  Starting Training...")
        logger.info("=" * 60 + "\n")
        
        # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        self.prepare_data()
        
        if mode == 'prepare':
            # Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙÙ‚Ø· (Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ù„Ø§Ø­Ù‚Ø§Ù‹)
            self.save_training_data()
            self._save_for_nodejs()
            
        elif mode == 'full':
            # ØªØ¯Ø±ÙŠØ¨ ÙƒØ§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬
            self._train_with_model()
        
        self.stats.end_time = time.time()
        
        logger.info("\n" + "=" * 60)
        logger.info(f"[OK] Training completed in {self.stats.duration:.1f} seconds")
        logger.info("=" * 60)
    
    def _save_for_nodejs(self):
        """Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨ØªÙ†Ø³ÙŠÙ‚ Ù…Ù†Ø§Ø³Ø¨ Ù„Ù€ Node.js"""
        # Ø­ÙØ¸ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
        knowledge_path = MODELS_DIR / "knowledge-base.json"
        
        knowledge = {
            'version': '1.0',
            'updated_at': datetime.now().isoformat(),
            'error_patterns': [
                {
                    'error': item['input'],
                    'fix': item['output'],
                    'type': item.get('error_type', 'general'),
                    'language': item.get('language', 'unknown')
                }
                for item in self.training_data['error_fixing']
            ],
            'qa_knowledge': [
                {
                    'question': item['input'],
                    'answer': item['output'],
                    'category': item.get('category', 'general')
                }
                for item in self.training_data['qa_pairs']
            ],
            'code_patterns': [
                {
                    'pattern': item.get('pattern', 'unknown'),
                    'code': item['output'],
                    'description': item['input']
                }
                for item in self.training_data['design_patterns']
            ]
        }
        
        with open(knowledge_path, 'w', encoding='utf-8') as f:
            json.dump(knowledge, f, ensure_ascii=False, indent=2)
        
        logger.info(f"\n[OK] Knowledge base saved: {knowledge_path}")
        
        # Ø­ÙØ¸ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ù…Ø­Ù„ÙŠØ©
        learned_path = DATA_DIR / "learned-knowledge.json"
        
        learned = {
            'updated_at': datetime.now().isoformat(),
            'training_stats': {
                'total_samples': self.stats.total_samples,
                'code_samples': self.stats.code_samples,
                'error_patterns': self.stats.error_patterns,
                'qa_pairs': self.stats.qa_pairs,
                'languages': self.stats.languages,
                'categories': self.stats.categories
            },
            'patterns': {
                'error_fixes': [
                    {'error': e['input'][:100], 'type': e.get('error_type')}
                    for e in self.training_data['error_fixing'][:100]
                ],
                'design_patterns': [
                    {'name': p.get('pattern'), 'language': 'javascript'}
                    for p in self.training_data['design_patterns']
                ]
            }
        }
        
        with open(learned_path, 'w', encoding='utf-8') as f:
            json.dump(learned, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ“ ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ù…ØªØ¹Ù„Ù…Ø©: {learned_path}")
    
    def _train_with_model(self):
        """ØªØ¯Ø±ÙŠØ¨ Ù…Ø¹ Ù†Ù…ÙˆØ°Ø¬ ML (ÙŠØªØ·Ù„Ø¨ transformers)"""
        try:
            from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments
            from transformers import Trainer as HFTrainer
            import torch
            
            logger.info("\nğŸ”„ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬...")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†Ù…ÙˆØ°Ø¬ ØµØºÙŠØ± Ù„Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø­Ù„ÙŠ
            model_name = "microsoft/CodeGPT-small-py"
            
            self.tokenizer = AutoTokenizer.from_pretrained(model_name)
            self.model = AutoModelForCausalLM.from_pretrained(model_name)
            
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ØªØ¯Ø±ÙŠØ¨
            # ... (ÙƒÙˆØ¯ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ù„ÙŠ)
            
            logger.info("[OK] Training successful!")
            
        except ImportError:
            logger.warning("[WARN] transformers library not available. Saving data only.")
            self.save_training_data()
            self._save_for_nodejs()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    """Ù†Ù‚Ø·Ø© Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"""
    
    # Ø·Ø¨Ø§Ø¹Ø© Ø§Ù„ØªØ±Ø­ÙŠØ¨
    print("\n")
    print("=" * 70)
    print("          Bi IDE - AI Training System")
    print("=" * 70)
    print("  Training: Code Understanding | Error Fixing | Development")
    print("=" * 70)
    print()
    
    # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ arguments
    parser = argparse.ArgumentParser(description='Bi IDE AI Training System')
    parser.add_argument('--mode', choices=['prepare', 'full'], default='prepare',
                       help='ÙˆØ¶Ø¹ Ø§Ù„ØªØ¯Ø±ÙŠØ¨: prepare (ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª) Ø£Ùˆ full (ØªØ¯Ø±ÙŠØ¨ ÙƒØ§Ù…Ù„)')
    parser.add_argument('--output', type=str, default=None,
                       help='Ù…Ø³Ø§Ø± Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬')
    parser.add_argument('--verbose', '-v', action='store_true',
                       help='Ø·Ø¨Ø§Ø¹Ø© ØªÙØ§ØµÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠØ©')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¯Ø±Ø¨ ÙˆØ¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    trainer = AITrainer()
    
    try:
        trainer.train(mode=args.mode)
        
        print("\n" + "-" * 70)
        print("[SUCCESS] Training Completed!")
        print()
        print("Files Created:")
        print(f"   - {OUTPUT_DIR / 'training_data.json'}")
        print(f"   - {MODELS_DIR / 'knowledge-base.json'}")
        print(f"   - {DATA_DIR / 'learned-knowledge.json'}")
        print()
        print("To use in Bi IDE, run:")
        print("   npm start")
        print("-" * 70 + "\n")
        
    except KeyboardInterrupt:
        print("\n\n[WARN] Training stopped by user.")
        sys.exit(1)
    except Exception as e:
        logger.error(f"[ERROR] Training error: {e}")
        raise


if __name__ == '__main__':
    main()
