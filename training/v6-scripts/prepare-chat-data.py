#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Bi IDE - ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (ChatML)
ÙŠØ­ÙˆÙ‘Ù„ Ø¨ÙŠØ§Ù†Ø§Øª instruction/output Ø¥Ù„Ù‰ ØµÙŠØºØ© Ù…Ø­Ø§Ø¯Ø«Ø© Ù…ØªØ¹Ø¯Ø¯Ø© Ø§Ù„Ø£Ø¯ÙˆØ§Ø± Ù„ØªØ¯Ø±ÙŠØ¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©.

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
    python training/prepare-chat-data.py
    python training/prepare-chat-data.py --max-length 1024 --out training/output/chat_training_data.json
"""

import json
import argparse
from pathlib import Path

BASE_DIR = Path(__file__).resolve().parent.parent
TRAINING_DIR = BASE_DIR / "training" / "output"
KNOWLEDGE_DIR = BASE_DIR / "data" / "knowledge"
OUTPUT_FILE = TRAINING_DIR / "chat_training_data.json"
SKIP_FILES = {
    "all_training_data.json", "validated_training_data.json",
    "validation_report.json", "training_report.json", "cleanup_summary.json",
    "chat_training_data.json"
}
MAX_CONTENT_LENGTH = 2048  # Ù…Ù†Ø§Ø³Ø¨ Ù„Ù€ Qwen2.5-3B


def get_instruction(item):
    return (
        item.get("instruction")
        or item.get("input")
        or item.get("question")
        or item.get("prompt")
        or ""
    )


def get_output(item):
    return (
        item.get("output")
        or item.get("answer")
        or item.get("response")
        or item.get("completion")
        or ""
    )


def load_rag_knowledge():
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ© RAG"""
    out = []
    rag_file = KNOWLEDGE_DIR / "rag-knowledge-base.json"
    if not rag_file.exists():
        return out
    try:
        with open(rag_file, "r", encoding="utf-8") as f:
            docs = json.load(f)
        for doc in docs:
            text = doc.get("text", "")
            answer = doc.get("answer", "")
            if text and answer:
                out.append({"instruction": text[:MAX_CONTENT_LENGTH], "output": answer[:MAX_CONTENT_LENGTH * 2]})
    except Exception as e:
        print(f"   âš ï¸ rag-knowledge-base.json: {e}")
    return out


def load_training_jsons(max_length):
    """ØªØ­Ù…ÙŠÙ„ ÙƒÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…Ù† training/output"""
    out = []
    if not TRAINING_DIR.exists():
        return out
    for path in sorted(TRAINING_DIR.glob("*.json")):
        if path.name in SKIP_FILES:
            continue
        try:
            with open(path, "r", encoding="utf-8") as f:
                data = json.load(f)
        except Exception as e:
            print(f"   âš ï¸ {path.name}: {e}")
            continue
        if isinstance(data, list):
            for item in data:
                inp = get_instruction(item)
                out_val = get_output(item)
                if inp and out_val:
                    out.append({
                        "instruction": str(inp)[:max_length],
                        "output": str(out_val)[:max_length * 2],
                    })
        elif isinstance(data, dict):
            if "samples" in data:
                for item in data["samples"]:
                    inp = get_instruction(item)
                    out_val = get_output(item)
                    if inp and out_val:
                        out.append({"instruction": str(inp)[:max_length], "output": str(out_val)[:max_length * 2]})
            elif "examples" in data:
                for item in data["examples"]:
                    inp = get_instruction(item)
                    out_val = get_output(item)
                    if inp and out_val:
                        out.append({"instruction": str(inp)[:max_length], "output": str(out_val)[:max_length * 2]})
    return out


def to_chatml_conversation(instruction, output):
    """ØªØ­ÙˆÙŠÙ„ Ø²ÙˆØ¬ Ø³Ø¤Ø§Ù„/Ø¬ÙˆØ§Ø¨ Ø¥Ù„Ù‰ Ù…Ø­Ø§Ø¯Ø«Ø© ChatML (Ù‚Ø§Ø¦Ù…Ø© Ø±Ø³Ø§Ø¦Ù„)."""
    return [
        {"role": "user", "content": instruction.strip()},
        {"role": "assistant", "content": output.strip()},
    ]


def main():
    parser = argparse.ArgumentParser(description="ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© ChatML")
    parser.add_argument("--max-length", type=int, default=1024, help="Ø£Ù‚ØµÙ‰ Ø·ÙˆÙ„ Ù„Ù„Ù…Ø­ØªÙˆÙ‰")
    parser.add_argument("--out", type=str, default=str(OUTPUT_FILE), help="Ù…Ù„Ù Ø§Ù„Ø¥Ø®Ø±Ø§Ø¬")
    parser.add_argument("--no-followup", action="store_true", help="Ø¨Ø¯ÙˆÙ† Ø¥Ø¶Ø§ÙØ© Ø¬Ù…Ù„ Ù…ØªØ§Ø¨Ø¹Ø©")
    args = parser.parse_args()
    out_path = Path(args.out)
    max_length = args.max_length

    print("=" * 50)
    print("Bi IDE â€“ ØªØ­Ø¶ÙŠØ± Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (ChatML)")
    print("=" * 50)

    conversations = []

    # 1. Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©
    print("\nğŸ“š ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ù…Ø¹Ø±ÙØ©...")
    rag = load_rag_knowledge()
    for item in rag:
        conversations.append(to_chatml_conversation(item["instruction"], item["output"]))
    print(f"   âœ… {len(rag)} Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ù† RAG")

    # 2. Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    print("\nğŸ“„ ØªØ­Ù…ÙŠÙ„ training/output/*.json...")
    raw = load_training_jsons(max_length)
    for item in raw:
        conversations.append(to_chatml_conversation(item["instruction"], item["output"]))
    print(f"   âœ… {len(raw)} Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ù† Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨")

    # Ø¥Ø²Ø§Ù„Ø© ØªÙƒØ±Ø§Ø±Ø§Øª ØªÙ‚Ø±ÙŠØ¨ÙŠØ© (Ù†ÙØ³ Ø£ÙˆÙ„ Ø±Ø³Ø§Ù„Ø© user)
    seen = set()
    unique = []
    for conv in conversations:
        key = conv[0]["content"][:200] if conv else ""
        if key not in seen:
            seen.add(key)
            unique.append(conv)
    if len(unique) < len(conversations):
        print(f"   ğŸ“Œ Ø¥Ø²Ø§Ù„Ø© ØªÙƒØ±Ø§Ø±Ø§Øª: {len(conversations) - len(unique)}")

    conversations = unique
    print(f"\nğŸ“Š Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹: {len(conversations)} Ù…Ø­Ø§Ø¯Ø«Ø© (ChatML)")

    out_path.parent.mkdir(parents=True, exist_ok=True)
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(conversations, f, ensure_ascii=False, indent=2)

    print(f"\nâœ… ØªÙ… Ø§Ù„Ø­ÙØ¸: {out_path}")
    print("   Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„ØªØ§Ù„ÙŠØ©: python training/finetune-chat.py")


if __name__ == "__main__":
    main()
