"""
Bi IDE â€“ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø´Ø§Ù…Ù„
Smart Learning Engine - ÙŠØ¨Ø­Ø« Ø£ÙˆÙ†Ù„Ø§ÙŠÙ† + ÙŠÙˆÙ„Ù‘Ø¯ training data + ÙŠØ¨Ù†ÙŠ embeddings + ÙŠØ¯Ø±Ù‘Ø¨

Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…:
  python training/smart-learn.py                    # ØªØ¹Ù„Ù… ÙƒÙ„ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø¨Ø§Ù„Ø·Ø§Ø¨ÙˆØ±
  python training/smart-learn.py --topic "React"    # ØªØ¹Ù„Ù… Ù…ÙˆØ¶ÙˆØ¹ ÙˆØ§Ø­Ø¯
  python training/smart-learn.py --curriculum web    # ØªØ¹Ù„Ù… Ù…Ù†Ù‡Ø¬ ÙƒØ§Ù…Ù„
  python training/smart-learn.py --train             # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙ‚Ø·
  python training/smart-learn.py --status            # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø©

ÙŠÙƒØªØ¨ Ø§Ù„ØªÙ‚Ø¯Ù… ÙÙŠ data/learning/smart-learn-progress.json (Bi IDE ÙŠÙ‚Ø±Ø£Ù‡)
"""

import json
import os
import sys
import time
import re
import hashlib
from pathlib import Path
from datetime import datetime

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

BASE_DIR = Path(__file__).parent.parent
DATA_DIR = BASE_DIR / "data"
LEARNING_DIR = DATA_DIR / "learning"
KNOWLEDGE_DIR = DATA_DIR / "knowledge"
TRAINING_DIR = BASE_DIR / "training" / "output"
MODELS_DIR = BASE_DIR / "models"

QUEUE_FILE = LEARNING_DIR / "learn-queue.json"
PROGRESS_FILE = LEARNING_DIR / "smart-learn-progress.json"
LEARNED_FILE = KNOWLEDGE_DIR / "smart-learned-data.json"
EMBEDDINGS_FILE = KNOWLEDGE_DIR / "smart-embeddings.json"

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ø¬Ù„Ø¯Ø§Øª
LEARNING_DIR.mkdir(parents=True, exist_ok=True)
KNOWLEDGE_DIR.mkdir(parents=True, exist_ok=True)
TRAINING_DIR.mkdir(parents=True, exist_ok=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

CURRICULA = {
    "js": {
        "name": "JavaScript Mastery",
        "topics": [
            "JavaScript variables let const var scope",
            "JavaScript functions arrow closures hoisting",
            "JavaScript promises async await error handling",
            "JavaScript classes inheritance prototypes OOP",
            "JavaScript modules import export ES6",
            "JavaScript array methods map filter reduce forEach",
            "JavaScript destructuring spread rest operator",
            "JavaScript event loop microtasks macrotasks",
            "JavaScript DOM manipulation events",
            "JavaScript fetch API HTTP requests",
            "JavaScript error handling try catch finally",
            "JavaScript regular expressions patterns",
            "JavaScript generators iterators symbols",
            "JavaScript proxy reflect metaprogramming",
            "JavaScript web workers service workers",
            "Node.js express REST API middleware",
            "Node.js file system streams buffers",
            "Node.js authentication JWT bcrypt sessions",
            "Node.js MongoDB Mongoose database",
            "Node.js testing Jest Mocha Chai",
        ]
    },
    "python": {
        "name": "Python Complete",
        "topics": [
            "Python data types variables strings lists dicts",
            "Python functions lambda decorators generators",
            "Python OOP classes inheritance polymorphism",
            "Python file handling reading writing CSV JSON",
            "Python exception handling try except finally",
            "Python list comprehension dict comprehension",
            "Python async programming asyncio await",
            "Python regular expressions re module",
            "Python NumPy arrays operations broadcasting",
            "Python Pandas DataFrame Series operations",
            "Python Flask web framework routing templates",
            "Python Django models views templates ORM",
            "Python FastAPI REST API async endpoints",
            "Python SQLAlchemy database ORM queries",
            "Python testing pytest unittest mocking",
            "Python machine learning scikit-learn basics",
            "Python PyTorch tensors neural networks",
            "Python web scraping BeautifulSoup requests",
            "Python automation scripts os subprocess",
            "Python packaging pip virtualenv setup",
        ]
    },
    "web": {
        "name": "Full Stack Web Development",
        "topics": [
            "HTML5 semantic elements forms accessibility",
            "CSS3 flexbox grid layout responsive design",
            "CSS animations transitions transforms",
            "React components JSX props state hooks",
            "React useState useEffect useContext useReducer",
            "React Router navigation dynamic routes",
            "React performance memo useMemo useCallback",
            "Vue.js components reactivity computed watchers",
            "Next.js SSR SSG ISR API routes",
            "TypeScript types interfaces generics enums",
            "REST API design best practices versioning",
            "GraphQL queries mutations subscriptions",
            "WebSocket real-time Socket.io implementation",
            "Authentication OAuth2 JWT session cookies",
            "MongoDB NoSQL document database queries",
            "PostgreSQL SQL joins indexes transactions",
            "Redis caching pub/sub session store",
            "Docker containers Dockerfile compose networking",
            "CI/CD GitHub Actions deployment pipelines",
            "Web security XSS CSRF SQL injection CORS",
        ]
    },
    "laravel": {
        "name": "Laravel PHP Framework",
        "topics": [
            "PHP 8 types match named arguments fibers",
            "Laravel routing controllers middleware groups",
            "Laravel Blade templates components layouts",
            "Laravel Eloquent ORM models relationships",
            "Laravel migrations seeders factories",
            "Laravel authentication Breeze Sanctum Passport",
            "Laravel authorization gates policies",
            "Laravel validation form requests rules",
            "Laravel file storage upload S3 local",
            "Laravel API resources JSON responses",
            "Laravel queues jobs workers scheduling",
            "Laravel events listeners notifications mail",
            "Laravel testing feature unit browser PHPUnit",
            "Laravel Livewire real-time components",
            "Laravel deployment optimization caching",
        ]
    },
    "security": {
        "name": "Security & DevOps",
        "topics": [
            "Linux command line bash scripting permissions",
            "Network security TCP/IP DNS firewalls",
            "Cryptography hashing encryption AES RSA",
            "Web security OWASP top 10 vulnerabilities",
            "Penetration testing methodology tools Kali",
            "Docker security best practices scanning",
            "Kubernetes basics pods services deployments",
            "Cloud security AWS IAM VPC security groups",
            "SSL TLS HTTPS certificate management",
            "Security logging monitoring SIEM tools",
        ]
    },
    "ai": {
        "name": "AI & Machine Learning",
        "topics": [
            "Machine learning supervised unsupervised basics",
            "Neural networks perceptron backpropagation",
            "Deep learning CNN image classification",
            "RNN LSTM sequence modeling text generation",
            "Transformer architecture attention mechanism",
            "NLP tokenization embeddings word2vec",
            "Large Language Models GPT BERT training",
            "Fine-tuning LLM LoRA QLoRA PEFT",
            "RAG retrieval augmented generation vector DB",
            "Model deployment ONNX TensorRT optimization",
            "PyTorch training pipeline DataLoader optimizer",
            "Hugging Face transformers pipeline usage",
            "Computer vision object detection YOLO",
            "Reinforcement learning Q-learning policy gradient",
            "AI ethics bias fairness safety alignment",
        ]
    },
    "survival": {
        "name": "Ø§Ù„Ø¨Ù‚Ø§Ø¡ Ø¨Ø¹Ø¯ Ø§Ù„ÙƒØ§Ø±Ø«Ø©",
        "topics": [
            "emergency survival shelter building techniques",
            "water purification filtration methods survival",
            "food preservation drying salting fermentation",
            "herbal medicine natural remedies first aid",
            "fire starting methods primitive tools survival",
            "navigation without GPS stars compass natural",
            "seed saving crop cultivation subsistence farming",
            "animal husbandry raising livestock chickens goats",
            "solar power DIY panels battery systems",
            "wind turbine construction alternative energy",
            "well digging water collection rainwater harvesting",
            "brick making construction mud stone building",
            "blacksmithing metal working tools weapons",
            "textile production weaving spinning cloth",
            "soap making candle making basic chemistry",
            "radio communication emergency broadcasting",
            "community governance conflict resolution",
            "basic surgery wound care field medicine",
            "food storage long term preservation techniques",
            "defense security perimeter protection",
        ]
    },
    "factory": {
        "name": "Ø§Ù„ØªØµÙ†ÙŠØ¹ Ù…Ù† Ø§Ù„ØµÙØ±",
        "topics": [
            "PCB design manufacturing etching soldering",
            "laptop motherboard assembly production line",
            "display screen LCD OLED manufacturing",
            "battery lithium ion cell assembly pack",
            "thermal management heatsink cooling design",
            "chassis mechanical design CNC machining",
            "BIOS firmware embedded programming",
            "quality testing reliability burn-in testing",
            "smartphone manufacturing assembly process",
            "solar panel manufacturing silicon wafer",
            "LED lighting manufacturing assembly",
            "electric motor winding assembly testing",
            "transformer manufacturing core winding",
            "Lean manufacturing Six Sigma quality",
            "factory ERP MES PLM WMS systems",
        ]
    }
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø¨Ø­Ø« Ø£ÙˆÙ†Ù„Ø§ÙŠÙ†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def search_online(query, max_results=10):
    """Ø¨Ø­Ø« Ø£ÙˆÙ†Ù„Ø§ÙŠÙ† ÙÙŠ Ø¹Ø¯Ø© Ù…ØµØ§Ø¯Ø±"""
    results = []
    
    # 1. StackOverflow
    try:
        import urllib.request
        import urllib.parse
        url = f"https://api.stackexchange.com/2.3/search?order=desc&sort=votes&intitle={urllib.parse.quote(query)}&site=stackoverflow&pagesize=5"
        req = urllib.request.Request(url, headers={'User-Agent': 'BiIDE/5.0', 'Accept-Encoding': 'identity'})
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = json.loads(resp.read().decode('utf-8'))
            for item in (data.get('items') or [])[:5]:
                results.append({
                    'source': 'stackoverflow',
                    'title': item.get('title', ''),
                    'content': item.get('title', ''),
                    'url': item.get('link', ''),
                    'score': item.get('score', 0),
                    'tags': item.get('tags', []),
                })
        print(f"  âœ… StackOverflow: {len(data.get('items', [])[:5])} Ù†ØªØ§Ø¦Ø¬")
    except Exception as e:
        print(f"  âš ï¸ StackOverflow: {e}")
    
    # 2. npm
    try:
        url = f"https://registry.npmjs.org/-/v1/search?text={urllib.parse.quote(query)}&size=5"
        req = urllib.request.Request(url, headers={'User-Agent': 'BiIDE/5.0'})
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = json.loads(resp.read().decode('utf-8'))
            for obj in (data.get('objects') or [])[:5]:
                pkg = obj.get('package', {})
                results.append({
                    'source': 'npm',
                    'title': pkg.get('name', ''),
                    'content': f"{pkg.get('description', '')}\nKeywords: {', '.join(pkg.get('keywords', []))}",
                    'url': f"https://www.npmjs.com/package/{pkg.get('name', '')}",
                    'score': obj.get('score', {}).get('final', 0),
                })
        print(f"  âœ… npm: {len(data.get('objects', [])[:5])} Ù†ØªØ§Ø¦Ø¬")
    except Exception as e:
        print(f"  âš ï¸ npm: {e}")
    
    # 3. GitHub
    try:
        url = f"https://api.github.com/search/repositories?q={urllib.parse.quote(query)}&sort=stars&per_page=5"
        req = urllib.request.Request(url, headers={'User-Agent': 'BiIDE/5.0'})
        with urllib.request.urlopen(req, timeout=10) as resp:
            data = json.loads(resp.read().decode('utf-8'))
            for repo in (data.get('items') or [])[:5]:
                results.append({
                    'source': 'github',
                    'title': repo.get('full_name', ''),
                    'content': f"{repo.get('description', '')}\nStars: {repo.get('stargazers_count', 0)}\nLanguage: {repo.get('language', 'N/A')}",
                    'url': repo.get('html_url', ''),
                    'score': repo.get('stargazers_count', 0),
                })
        print(f"  âœ… GitHub: {len(data.get('items', [])[:5])} Ù†ØªØ§Ø¦Ø¬")
    except Exception as e:
        print(f"  âš ï¸ GitHub: {e}")
    
    return results

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_training_data(topic, search_results):
    """ÙŠÙˆÙ„Ù‘Ø¯ Ø£Ø²ÙˆØ§Ø¬ instruction/output Ù…Ù† Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø¨Ø­Ø«"""
    pairs = []
    
    for result in search_results:
        text = f"{result['title']}\n{result['content']}".strip()
        if len(text) < 20:
            continue
        
        # Ù†Ù…Ø· 1: Ø§Ø´Ø±Ø­ Ø§Ù„Ù…ÙˆØ¶ÙˆØ¹
        pairs.append({
            'instruction': f"Ø§Ø´Ø±Ø­ {topic}",
            'input': '',
            'output': text[:500],
            'metadata': {'source': result['source'], 'topic': topic, 'type': 'explain'}
        })
        
        # Ù†Ù…Ø· 2: Ù…Ø§ Ù‡Ùˆ
        pairs.append({
            'instruction': f"What is {topic}?",
            'input': '',
            'output': text[:500],
            'metadata': {'source': result['source'], 'topic': topic, 'type': 'what-is'}
        })
        
        # Ù†Ù…Ø· 3: Ø£Ù…Ø«Ù„Ø©
        if result.get('tags'):
            pairs.append({
                'instruction': f"Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ù€ {topic}?",
                'input': '',
                'output': f"Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª: {', '.join(result['tags'][:10])}",
                'metadata': {'source': result['source'], 'topic': topic, 'type': 'related'}
            })
        
        # Ù†Ù…Ø· 4: Ù…Ù‚Ø§Ø±Ù†Ø©
        if result['source'] == 'github' and result.get('score', 0) > 100:
            pairs.append({
                'instruction': f"Ù…Ø§ Ø£ÙØ¶Ù„ Ù…Ø´Ø±ÙˆØ¹ Ù…ÙØªÙˆØ­ Ø§Ù„Ù…ØµØ¯Ø± Ù„Ù€ {topic}?",
                'input': '',
                'output': f"{result['title']} - {result['content'][:300]}",
                'metadata': {'source': 'github', 'topic': topic, 'type': 'recommendation'}
            })
    
    return pairs

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ØªØ¹Ù„Ù… Ù…ÙˆØ¶ÙˆØ¹ ÙˆØ§Ø­Ø¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def learn_topic(topic, progress_callback=None):
    """ØªØ¹Ù„Ù… Ù…ÙˆØ¶ÙˆØ¹ ÙˆØ§Ø­Ø¯: Ø¨Ø­Ø« â†’ ØªÙˆÙ„ÙŠØ¯ â†’ Ø­ÙØ¸"""
    print(f"\nğŸ“– ØªØ¹Ù„Ù‘Ù…: {topic}")
    
    # 1. Ø¨Ø­Ø« Ø£ÙˆÙ†Ù„Ø§ÙŠÙ†
    print("  ğŸŒ Ø¨Ø­Ø« Ø£ÙˆÙ†Ù„Ø§ÙŠÙ†...")
    results = search_online(topic)
    
    if not results:
        print("  âš ï¸ Ù„Ø§ Ù†ØªØ§Ø¦Ø¬ - ØªØ®Ø·ÙŠ")
        return {'topic': topic, 'status': 'no_results', 'pairs': 0}
    
    # 2. ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨
    print("  ğŸ“ ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨...")
    pairs = generate_training_data(topic, results)
    
    # 3. Ø­ÙØ¸
    save_training_data(pairs)
    
    print(f"  âœ… {len(pairs)} Ø²ÙˆØ¬ ØªØ¯Ø±ÙŠØ¨ÙŠ + {len(results)} Ù†ØªÙŠØ¬Ø© Ø¨Ø­Ø«")
    
    return {'topic': topic, 'status': 'completed', 'pairs': len(pairs), 'results': len(results)}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø­ÙØ¸ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def save_training_data(new_pairs):
    """Ø¥Ø¶Ø§ÙØ© Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ø¬Ø¯ÙŠØ¯Ø©"""
    existing = []
    if LEARNED_FILE.exists():
        try:
            with open(LEARNED_FILE, 'r', encoding='utf-8') as f:
                existing = json.load(f)
        except:
            existing = []
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
    existing_keys = set()
    for item in existing:
        key = hashlib.md5(f"{item.get('instruction','')}|{item.get('output','')[:50]}".encode()).hexdigest()
        existing_keys.add(key)
    
    added = 0
    for pair in new_pairs:
        key = hashlib.md5(f"{pair.get('instruction','')}|{pair.get('output','')[:50]}".encode()).hexdigest()
        if key not in existing_keys:
            existing.append(pair)
            existing_keys.add(key)
            added += 1
    
    # Ø­Ø¯ Ø£Ù‚ØµÙ‰ 50000
    if len(existing) > 50000:
        existing = existing[-50000:]
    
    with open(LEARNED_FILE, 'w', encoding='utf-8') as f:
        json.dump(existing, f, ensure_ascii=False, indent=1)
    
    # Ù†Ø³Ø®Ø© Ù„Ù€ training/output Ø£ÙŠØ¶Ø§Ù‹
    training_copy = TRAINING_DIR / "smart_learned_training.json"
    with open(training_copy, 'w', encoding='utf-8') as f:
        json.dump(existing, f, ensure_ascii=False, indent=1)
    
    return added

def update_progress(state):
    """ØªØ­Ø¯ÙŠØ« Ù…Ù„Ù Ø§Ù„ØªÙ‚Ø¯Ù… (Bi IDE ÙŠÙ‚Ø±Ø£Ù‡)"""
    state['updated_at'] = datetime.now().isoformat()
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump(state, f, ensure_ascii=False, indent=2)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø­ÙØ¸/Ø§Ø³ØªØ¹Ø§Ø¯Ø© Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© (resume)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

COMPLETED_FILE = LEARNING_DIR / "completed-topics.json"

def load_completed_topics():
    """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹"""
    if COMPLETED_FILE.exists():
        try:
            with open(COMPLETED_FILE, 'r', encoding='utf-8') as f:
                return set(json.load(f))
        except:
            pass
    return set()

def save_completed_topic(topic, completed_set):
    """Ø­ÙØ¸ Ù…ÙˆØ¶ÙˆØ¹ Ù…ÙƒØªÙ…Ù„"""
    completed_set.add(topic)
    with open(COMPLETED_FILE, 'w', encoding='utf-8') as f:
        json.dump(list(completed_set), f, ensure_ascii=False)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„ÙØ¹Ù„ÙŠ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def train_model():
    """ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø¨ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¬Ù…Ø¹Ø©"""
    print("\n" + "=" * 50)
    print("ğŸš€ Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬")
    print("=" * 50)
    
    # Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    all_data = []
    
    for json_file in TRAINING_DIR.glob("*.json"):
        if json_file.name == "training_report.json":
            continue
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            if isinstance(data, list):
                valid = [d for d in data if d.get('instruction') and d.get('output')]
                all_data.extend(valid)
        except:
            pass
    
    # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø¹Ø±ÙØ©
    for kb_file in ['rag-knowledge-base.json', 'smart-learned-data.json']:
        kb_path = KNOWLEDGE_DIR / kb_file
        if kb_path.exists():
            try:
                with open(kb_path, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                if isinstance(data, list):
                    for d in data:
                        if d.get('instruction') and d.get('output'):
                            all_data.append(d)
                        elif d.get('text') and d.get('answer'):
                            all_data.append({'instruction': d['text'][:200], 'output': d['answer'][:500]})
            except:
                pass
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„ØªÙƒØ±Ø§Ø±
    seen = set()
    unique = []
    for item in all_data:
        key = f"{item['instruction'][:30]}|{item['output'][:30]}"
        if key not in seen:
            seen.add(key)
            unique.append(item)
    
    print(f"ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {len(unique)} Ø¹ÙŠÙ†Ø© ÙØ±ÙŠØ¯Ø©")
    
    if len(unique) < 50:
        print("âŒ Ø¨ÙŠØ§Ù†Ø§Øª Ù‚Ù„ÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹. ØªØ¹Ù„Ù… Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø£ÙƒØ«Ø± Ø£ÙˆÙ„Ø§Ù‹.")
        return False
    
    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ auto-finetune
    try:
        import subprocess
        script = BASE_DIR / "training" / "auto-finetune.py"
        result = subprocess.run(
            [sys.executable, str(script)],
            cwd=str(BASE_DIR),
            capture_output=False
        )
        return result.returncode == 0
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ Ø¨Ø§Ù„ØªØ¯Ø±ÙŠØ¨: {e}")
        return False

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Main
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    args = sys.argv[1:]
    
    print("â•" * 50)
    print("ğŸ§  Bi IDE - Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ Ø§Ù„Ø´Ø§Ù…Ù„")
    print("â•" * 50)
    
    # Ø¹Ø±Ø¶ Ø§Ù„Ø­Ø§Ù„Ø© ÙÙ‚Ø·
    if '--status' in args:
        if LEARNED_FILE.exists():
            with open(LEARNED_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"ğŸ“Š Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ù„Ù‘Ù…Ø©: {len(data)} Ø¹ÙŠÙ†Ø©")
        else:
            print("ğŸ“Š Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…ØªØ¹Ù„Ù‘Ù…Ø© Ø¨Ø¹Ø¯")
        
        if PROGRESS_FILE.exists():
            with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
                progress = json.load(f)
            print(f"ğŸ“ˆ Ø¢Ø®Ø± ØªØ­Ø¯ÙŠØ«: {progress.get('updated_at', 'N/A')}")
            print(f"   Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…ÙƒØªÙ…Ù„Ø©: {progress.get('completed', 0)}")
            print(f"   Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨: {progress.get('total_pairs', 0)}")
        
        print(f"\nØ§Ù„Ù…Ù†Ø§Ù‡Ø¬ Ø§Ù„Ù…ØªØ§Ø­Ø©:")
        for cid, cur in CURRICULA.items():
            print(f"  {cid}: {cur['name']} ({len(cur['topics'])} Ù…ÙˆØ¶ÙˆØ¹)")
        return
    
    # ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙÙ‚Ø·
    if '--train' in args:
        train_model()
        return
    
    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹
    topics = []
    
    # Ù…ÙˆØ¶ÙˆØ¹ ÙˆØ§Ø­Ø¯
    if '--topic' in args:
        idx = args.index('--topic')
        if idx + 1 < len(args):
            topics = [args[idx + 1]]
    
    # Ù…Ù†Ù‡Ø¬ ÙƒØ§Ù…Ù„
    elif '--curriculum' in args:
        idx = args.index('--curriculum')
        if idx + 1 < len(args):
            cur_id = args[idx + 1]
            if cur_id == 'all':
                for cur in CURRICULA.values():
                    topics.extend(cur['topics'])
                print(f"ğŸ“š ÙƒÙ„ Ø§Ù„Ù…Ù†Ø§Ù‡Ø¬: {len(topics)} Ù…ÙˆØ¶ÙˆØ¹")
            elif cur_id in CURRICULA:
                topics = CURRICULA[cur_id]['topics']
                print(f"ğŸ“š Ù…Ù†Ù‡Ø¬: {CURRICULA[cur_id]['name']} ({len(topics)} Ù…ÙˆØ¶ÙˆØ¹)")
            else:
                print(f"âŒ Ù…Ù†Ù‡Ø¬ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯: {cur_id}")
                print(f"   Ø§Ù„Ù…ØªØ§Ø­: {', '.join(CURRICULA.keys())}, all")
                return
    
    # Ø¨Ø¯ÙˆÙ† arguments â†’ Ø£ÙˆÙ„ Ù…Ù†Ù‡Ø¬
    else:
        # ØªØ­Ù…ÙŠÙ„ Ø£ÙˆÙ„ Ù…Ù†Ù‡Ø¬ ÙƒØ§ÙØªØ±Ø§Ø¶ÙŠ
        first = list(CURRICULA.keys())[0]
        topics = CURRICULA[first]['topics']
        print(f"ğŸ“š Ø§ÙØªØ±Ø§Ø¶ÙŠ: {CURRICULA[first]['name']} ({len(topics)} Ù…ÙˆØ¶ÙˆØ¹)")
        print(f"   Ø§Ø³ØªØ®Ø¯Ù… --curriculum <id> Ù„Ù…Ù†Ù‡Ø¬ Ø¢Ø®Ø±")
        print(f"   Ø§Ù„Ù…ØªØ§Ø­: {', '.join(CURRICULA.keys())}, all")
    
    if not topics:
        print("âŒ Ù„Ø§ Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…Ø­Ø¯Ø¯Ø©")
        return
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø§Ù„Ù…ÙƒØªÙ…Ù„Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹ (resume)
    completed_set = load_completed_topics()
    remaining = [t for t in topics if t not in completed_set]
    skipped = len(topics) - len(remaining)
    
    if skipped > 0:
        print(f"â­ï¸ ØªØ®Ø·ÙŠ {skipped} Ù…ÙˆØ¶ÙˆØ¹ Ù…ÙƒØªÙ…Ù„ Ø³Ø§Ø¨Ù‚Ø§Ù‹")
    
    if not remaining:
        print("âœ… ÙƒÙ„ Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ Ù…ÙƒØªÙ…Ù„Ø©! Ø§Ø³ØªØ®Ø¯Ù… --reset Ù„Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¨Ø¯Ø¡")
        if '--reset' in args:
            completed_set = set()
            if COMPLETED_FILE.exists():
                COMPLETED_FILE.unlink()
            remaining = topics
            print("ğŸ”„ ØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ¹ÙŠÙŠÙ†")
        else:
            return
    
    # Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¹Ù„Ù…
    progress = {
        'state': 'running',
        'total': len(topics),
        'completed': skipped,
        'failed': 0,
        'total_pairs': 0,
        'total_results': 0,
        'current_topic': '',
        'remaining': len(remaining),
        'started_at': datetime.now().isoformat(),
    }
    update_progress(progress)
    
    print(f"\nğŸš€ Ø¨Ø¯Ø¡ ØªØ¹Ù„Ù‘Ù… {len(remaining)} Ù…ÙˆØ¶ÙˆØ¹ ({skipped} Ù…ÙƒØªÙ…Ù„ Ø³Ø§Ø¨Ù‚Ø§Ù‹)...\n")
    
    for i, topic in enumerate(remaining):
        progress['current_topic'] = topic
        progress['current_index'] = skipped + i + 1
        update_progress(progress)
        
        try:
            result = learn_topic(topic)
            
            if result['status'] == 'completed':
                progress['completed'] += 1
                progress['total_pairs'] += result['pairs']
                progress['total_results'] += result['results']
                save_completed_topic(topic, completed_set)
            else:
                progress['failed'] += 1
            
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸ Ø£ÙˆÙ‚Ù Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… - Ø§Ù„ØªÙ‚Ø¯Ù… Ù…Ø­ÙÙˆØ¸!")
            print(f"   Ù…ÙƒØªÙ…Ù„: {progress['completed']}/{progress['total']}")
            print(f"   Ø´ØºÙ‘Ù„ Ù†ÙØ³ Ø§Ù„Ø£Ù…Ø± Ù…Ø±Ø© Ø«Ø§Ù†ÙŠØ© Ù„ÙŠÙƒÙ…Ù„ Ù…Ù† Ù‡Ù†Ø§")
            progress['state'] = 'stopped'
            update_progress(progress)
            break
        except Exception as e:
            print(f"  âŒ Ø®Ø·Ø£: {e}")
            progress['failed'] += 1
        
        # ØªÙ‚Ø¯Ù…
        total_done = skipped + i + 1
        pct = round((total_done / len(topics)) * 100)
        print(f"  ğŸ“Š Ø§Ù„ØªÙ‚Ø¯Ù…: {pct}% ({total_done}/{len(topics)})")
        
        # Ø±Ø§Ø­Ø© Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ§Ø¶ÙŠØ¹ (rate limiting)
        if i < len(remaining) - 1:
            time.sleep(2)
    
    # Ø§ÙƒØªÙ…Ø§Ù„
    if progress['state'] != 'stopped':
        progress['state'] = 'completed'
        progress['completed_at'] = datetime.now().isoformat()
    update_progress(progress)
    
    print("\n" + "=" * 50)
    print(f"âœ… Ø§ÙƒØªÙ…Ù„: {progress['completed']}/{progress['total']} Ù…ÙˆØ¶ÙˆØ¹")
    print(f"ğŸ“ Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨: {progress['total_pairs']} Ø²ÙˆØ¬")
    print(f"ğŸŒ Ù†ØªØ§Ø¦Ø¬ Ø¨Ø­Ø«: {progress['total_results']}")
    print("=" * 50)
    
    # Ø³Ø¤Ø§Ù„ Ø¹Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨
    if progress['total_pairs'] > 100:
        print(f"\nğŸ’¡ Ø¹Ù†Ø¯Ùƒ {progress['total_pairs']} Ø¨ÙŠØ§Ù†Ø§Øª ØªØ¯Ø±ÙŠØ¨ Ø¬Ø¯ÙŠØ¯Ø©.")
        print(f"   Ø´ØºÙ‘Ù„: python training/smart-learn.py --train")
        print(f"   Ø£Ùˆ: python training/auto-finetune.py")

if __name__ == "__main__":
    main()
