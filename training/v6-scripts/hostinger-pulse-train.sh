#!/usr/bin/env bash
set -euo pipefail

# Bi IDE - Hostinger Pulse Training Runner
# ØªØ´ØºÙŠÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¨Ù†Ø¨Ø¶Ø§Øª Ù„ØªÙØ§Ø¯ÙŠ Ø®ÙØ¶ Ø£Ø¯Ø§Ø¡ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø¹Ù„Ù‰ Hostinger.
# Ø§Ù„ÙÙƒØ±Ø©: 150 Ø¯Ù‚ÙŠÙ‚Ø© â€œÙ†Ø´Ø§Ø· Ù…Ù†Ø®ÙØ¶/Ù…Ù‚ÙŠÙ‘Ø¯â€ + 45 Ø¯Ù‚ÙŠÙ‚Ø© ØªÙ‡Ø¯Ø¦Ø©ØŒ Ù…Ø¹ Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± Ø¨Ø¹Ø¯ Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

BASE_DIR="$(cd "$(dirname "$0")/.." && pwd)"
cd "$BASE_DIR"

# Python interpreter (prefer project venv)
PYTHON="${PYTHON:-}"
if [[ -z "$PYTHON" ]]; then
  if [[ -x "$BASE_DIR/venv/bin/python3" ]]; then
    PYTHON="$BASE_DIR/venv/bin/python3"
  elif command -v python3 >/dev/null 2>&1; then
    PYTHON="$(command -v python3)"
  elif command -v python >/dev/null 2>&1; then
    PYTHON="$(command -v python)"
  else
    echo "âŒ Python ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ (Ù„Ø§ python3 ÙˆÙ„Ø§ venv)." >&2
    exit 1
  fi
fi

# === Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¨Ø¶Ø§Øª ===
PULSE_TRAIN_MINUTES="${PULSE_TRAIN_MINUTES:-150}"
PULSE_REST_MINUTES="${PULSE_REST_MINUTES:-45}"

# === ØªÙ‚ÙŠÙŠØ¯ Ø§Ù„Ø¶ØºØ· (threads + nice) ===
CPU_THREADS="${CPU_THREADS:-6}"
NUM_WORKERS="${NUM_WORKERS:-4}"
NICE_LEVEL="${NICE_LEVEL:-10}"

# === ØªÙ‚Ø³ÙŠÙ… Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ (Ù„Ù„Ø³Ø­Ø¨ Ø¨Ø¯ÙˆÙ† ØªÙˆÙ‚Ù) ===
ARTIFACT_PART_MB="${ARTIFACT_PART_MB:-500}"
ARTIFACTS_DIR="${ARTIFACTS_DIR:-$BASE_DIR/training/artifacts}"

# === Ù…Ù„ÙØ§Øª Ø­Ø§Ù„Ø© ===
STATE_FILE="${STATE_FILE:-$BASE_DIR/training/output/hostinger-pulse-state.json}"
LOCK_FILE="${LOCK_FILE:-$BASE_DIR/training/output/hostinger-pulse.lock}"

mkdir -p "$(dirname "$STATE_FILE")" "$ARTIFACTS_DIR"

log() {
  echo "[$(date '+%F %T')] $*"
}

acquire_lock() {
  if (set -o noclobber; echo "$$" > "$LOCK_FILE") 2>/dev/null; then
    trap 'rm -f "$LOCK_FILE"' EXIT
    return 0
  fi
  log "âš ï¸ ÙŠÙˆØ¬Ø¯ ØªØ´ØºÙŠÙ„ Ø¢Ø®Ø± (lock Ù…ÙˆØ¬ÙˆØ¯): $LOCK_FILE"
  exit 0
}

read_progress_json() {
  # ÙŠØ·Ø¨Ø¹ JSON Ø¨Ø³ÙŠØ· Ø¹Ù† Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø¥Ø°Ø§ ÙˆØ¬Ø¯ trainer_state.json
  "$PYTHON" - <<'PY'
import json
from pathlib import Path

base = Path('.')
root = base / 'models' / 'finetuned'

def newest_trainer_state():
    if not root.exists():
        return None
    states = list(root.glob('checkpoint-*/trainer_state.json'))
    if not states:
        return None
    states.sort(key=lambda p: p.stat().st_mtime, reverse=True)
    return states[0]

p = newest_trainer_state()
if not p:
    print(json.dumps({"found": False}))
    raise SystemExit(0)

try:
    data = json.loads(p.read_text(encoding='utf-8'))
except Exception:
    print(json.dumps({"found": True, "path": str(p), "parse": False}))
    raise SystemExit(0)

out = {
  "found": True,
  "path": str(p),
  "global_step": data.get('global_step'),
  "max_steps": data.get('max_steps'),
  "epoch": data.get('epoch'),
  "best_global_step": data.get('best_global_step'),
  "best_metric": data.get('best_metric'),
}
print(json.dumps(out, ensure_ascii=False))
PY
}

should_stop_forever() {
  # ÙŠÙˆÙ‚Ù Ù†Ù‡Ø§Ø¦ÙŠØ§Ù‹ Ø¥Ø°Ø§ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ù…ÙƒØªÙ…Ù„ Ø­Ø³Ø¨ global_step/max_steps
  local progress
  progress="$(read_progress_json)"

  "$PYTHON" - <<PY
import json
data = json.loads('''$progress''')
gs = data.get('global_step')
ms = data.get('max_steps')
if isinstance(gs, int) and isinstance(ms, int) and ms > 0 and gs >= ms:
    print('YES')
else:
    print('NO')
PY
}

package_artifacts() {
  # ÙŠØ¹Ø¨Ù‘ÙŠ artifacts Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡ 500MB Ù„ØªØ³Ù‡ÙŠÙ„ Ø§Ù„Ø³Ø­Ø¨ Ø¨Ø¯ÙˆÙ† ØªÙˆÙ‚Ù.
  # Ù…Ø§ ÙŠØºÙŠÙ‘Ø± Ø£ÙŠ Ø´ÙŠØ¡ Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§ØªØ› ÙÙ‚Ø· Ù†Ø³Ø®/Ø£Ø±Ø´ÙØ©.
  local stamp out_dir
  stamp="$(date '+%F_%H%M%S')"
  out_dir="$ARTIFACTS_DIR/$stamp"
  mkdir -p "$out_dir"

  log "ğŸ“¦ Packaging artifacts (parts=${ARTIFACT_PART_MB}MB) â†’ $out_dir"
  "$PYTHON" "training/package-artifacts.py" \
    --output "$out_dir" \
    --part-mb "$ARTIFACT_PART_MB" \
    --include "models/finetuned" \
    --include "models/bi-ai-onnx" \
    --include "models/model-registry.json" \
    --include "training/output" \
    --max-output-gb "50" \
    --state "$STATE_FILE" \
    || true
}

run_one_pulse() {
  log "ğŸš€ Pulse start: train=${PULSE_TRAIN_MINUTES}min, rest=${PULSE_REST_MINUTES}min"

  export CPU_THREADS NUM_WORKERS
  export OMP_NUM_THREADS="$CPU_THREADS"
  export MKL_NUM_THREADS="$CPU_THREADS"
  export OPENBLAS_NUM_THREADS="$CPU_THREADS"
  export VECLIB_MAXIMUM_THREADS="$CPU_THREADS"
  export NUMEXPR_NUM_THREADS="$CPU_THREADS"

  # Ø¥ÙŠÙ‚Ø§Ù ØªØ¯Ø±ÙŠØ¬ÙŠ Ø¯Ø§Ø®Ù„ finetune.py Ø¨Ø¹Ø¯ Ù…Ø¯Ø© Ø§Ù„Ù†Ø¨Ø¶Ø© (ÙŠØ­ÙØ¸ checkpoint)
  export PULSE_MAX_MINUTES="$PULSE_TRAIN_MINUTES"

  # ØªØ´ØºÙŠÙ„ Ø¯ÙˆØ±Ø© ÙˆØ§Ø­Ø¯Ø© Ù…Ù† pipeline (Ø¬Ù…Ø¹ + ØªØ­Ù‚Ù‚ + finetune + onnx)
  # Ù†Ø®Ù„ÙŠÙ‡Ø§ Ø¨nice Ø­ØªÙ‰ ÙŠÙ‚Ù„ Ø§Ù„Ø¶ØºØ·.
  nice -n "$NICE_LEVEL" "$PYTHON" training/continuous-train.py || true

  package_artifacts

  log "ğŸ§Š Rest/Throttle: ${PULSE_REST_MINUTES}min"
  sleep "$((PULSE_REST_MINUTES * 60))"
}

main() {
  acquire_lock
  log "âœ… Hostinger pulse runner started (PID=$$)"

  while true; do
    if [[ "$(should_stop_forever)" == "YES" ]]; then
      log "âœ… Training complete (global_step >= max_steps). Stopping service."
      package_artifacts
      exit 0
    fi
    run_one_pulse
  done
}

main "$@"
