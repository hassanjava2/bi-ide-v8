#!/usr/bin/env python3
"""
ğŸ”§ BI-IDE Worker Agent â€” Ø¹Ù‚Ø¯Ø© ØªØ¯Ø±ÙŠØ¨ Ù…ÙˆØ²Ø¹Ø©

ÙŠØªÙ†ØµØ¨ Ø¹Ù„Ù‰ Ø£ÙŠ Ø­Ø§Ø³Ø¨Ø© ÙˆÙŠØªØµÙ„ Ø¨Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ.
ÙŠÙƒØªØ´Ù Ø§Ù„Ù‡Ø§Ø±Ø¯ÙˆÙŠØ± ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ ÙˆÙŠØ¨Ø¯Ø£ Ø§Ù„ØªØ¯Ø±ÙŠØ¨.

Features:
- Hardware auto-detection (GPU/CPU/RAM/OS)
- WebSocket + HTTP heartbeat (dual mode)
- Auto-reconnect on disconnect/restart
- Resource-limited training (--max-cpu, --max-gpu, --max-ram)
- Checkpoint upload to server
- Auto-sync to primary node (RTX 5090)

Usage:
    python bi_worker.py --server https://bi-iq.com --token TOKEN --labels gpu,rtx5090,primary
    python bi_worker.py --server https://bi-iq.com --token TOKEN --labels cpu,windows,helper
"""

from __future__ import annotations

import argparse
import asyncio
import hashlib
import json
import os
import platform
import signal
import socket
import subprocess
import sys
import time
import traceback
from datetime import datetime, timezone
from pathlib import Path
from typing import Any, Dict, List, Optional

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Dependencies â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

try:
    import requests
except ImportError:
    print("Installing requests...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "requests", "-q"])
    import requests

try:
    import psutil
except ImportError:
    print("Installing psutil...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "psutil", "-q"])
    import psutil

try:
    import websockets
except ImportError:
    print("Installing websockets...")
    subprocess.check_call([sys.executable, "-m", "pip", "install", "websockets", "-q"])
    import websockets


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Hardware Detection â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def detect_hardware() -> Dict[str, Any]:
    """Detect all hardware capabilities."""
    hw = {
        "cpu_name": platform.processor() or "unknown",
        "cpu_cores": psutil.cpu_count(logical=True),
        "cpu_cores_physical": psutil.cpu_count(logical=False),
        "ram_gb": round(psutil.virtual_memory().total / (1024**3), 1),
        "disk_gb": round(psutil.disk_usage("/").total / (1024**3), 1),
        "os_type": _detect_os(),
        "os_version": platform.platform(),
        "hostname": socket.gethostname(),
        "python_version": platform.python_version(),
        "gpu": detect_gpu(),
    }
    return hw


def detect_gpu() -> Dict[str, Any]:
    """Detect GPU info (NVIDIA via nvidia-smi, Apple via system_profiler)."""
    gpu_info = {"name": "none", "vram_gb": 0, "cuda_available": False, "driver_version": ""}

    # Try PyTorch CUDA
    try:
        import torch
        if torch.cuda.is_available():
            gpu_info["name"] = torch.cuda.get_device_name(0)
            props = torch.cuda.get_device_properties(0)
            vram = getattr(props, 'total_memory', None) or getattr(props, 'total_mem', 0)
            gpu_info["vram_gb"] = round(vram / (1024**3), 1)
            gpu_info["cuda_available"] = True
            return gpu_info
    except ImportError:
        pass

    # Try nvidia-smi
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=name,memory.total,driver_version",
             "--format=csv,noheader,nounits"],
            capture_output=True, text=True, timeout=5,
        )
        if result.returncode == 0:
            parts = result.stdout.strip().split(",")
            if len(parts) >= 3:
                gpu_info["name"] = parts[0].strip()
                gpu_info["vram_gb"] = round(float(parts[1].strip()) / 1024, 1)
                gpu_info["driver_version"] = parts[2].strip()
                gpu_info["cuda_available"] = True
    except Exception:
        pass

    # Try Apple Metal (M-series)
    if platform.system() == "Darwin":
        try:
            result = subprocess.run(
                ["system_profiler", "SPDisplaysDataType"],
                capture_output=True, text=True, timeout=5,
            )
            if result.returncode == 0:
                for line in result.stdout.split("\n"):
                    if "Chipset" in line or "Chip" in line:
                        gpu_info["name"] = line.split(":")[-1].strip()
                        break
                # Apple unified memory
                gpu_info["vram_gb"] = round(psutil.virtual_memory().total / (1024**3), 1)
        except Exception:
            pass

    return gpu_info


def _detect_os() -> str:
    s = platform.system().lower()
    if s == "darwin":
        return "macos"
    return s  # linux, windows


def get_resource_usage() -> Dict[str, Any]:
    """Get current resource usage."""
    usage = {
        "cpu_percent": psutil.cpu_percent(interval=0.5),
        "ram_percent": psutil.virtual_memory().percent,
        "ram_used_gb": round(psutil.virtual_memory().used / (1024**3), 1),
        "disk_percent": psutil.disk_usage("/").percent,
        "gpu_percent": 0,
        "gpu_mem_percent": 0,
        "gpu_temp_c": 0,
    }

    # GPU usage via nvidia-smi
    try:
        result = subprocess.run(
            ["nvidia-smi", "--query-gpu=utilization.gpu,utilization.memory,temperature.gpu",
             "--format=csv,noheader,nounits"],
            capture_output=True, text=True, timeout=5,
        )
        if result.returncode == 0:
            parts = result.stdout.strip().split(",")
            if len(parts) >= 3:
                usage["gpu_percent"] = float(parts[0].strip())
                usage["gpu_mem_percent"] = float(parts[1].strip())
                usage["gpu_temp_c"] = float(parts[2].strip())
    except Exception:
        pass

    return usage


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Worker Agent â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class WorkerAgent:
    """
    BI-IDE Worker Agent.
    Connects to the orchestrator, sends heartbeats, executes training jobs.
    """

    def __init__(self, server_url: str, token: str, labels: List[str],
                 worker_id: str = "", max_cpu: float = 90, max_gpu: float = 95,
                 max_ram: float = 85, heartbeat_interval: int = 30):
        self.server = server_url.rstrip("/")
        self.token = token
        self.labels = labels
        self.worker_id = worker_id or socket.gethostname()
        self.max_cpu = max_cpu
        self.max_gpu = max_gpu
        self.max_ram = max_ram
        self.heartbeat_interval = heartbeat_interval
        self.hardware = detect_hardware()
        self.running = True
        self.current_job = None
        self.training_process = None
        self.ws = None
        self.reconnect_delay = 5

        # Data directory
        self.data_dir = Path.home() / ".bi-ide-worker" / "data"
        self.data_dir.mkdir(parents=True, exist_ok=True)
        self.checkpoints_dir = self.data_dir / "checkpoints"
        self.checkpoints_dir.mkdir(exist_ok=True)

    @property
    def headers(self) -> Dict[str, str]:
        return {
            "X-Orchestrator-Token": self.token,
            "Content-Type": "application/json",
        }

    def register(self) -> bool:
        """Register this worker with the orchestrator."""
        try:
            resp = requests.post(
                f"{self.server}/api/v1/orchestrator/workers/register",
                json={
                    "worker_id": self.worker_id,
                    "hostname": socket.gethostname(),
                    "labels": self.labels,
                    "hardware": self.hardware,
                    "version": "1.0.0",
                },
                headers=self.headers,
                timeout=10,
            )
            if resp.status_code == 200:
                data = resp.json()
                self.worker_id = data.get("worker_id", self.worker_id)
                role = data.get("role", "helper")
                print(f"ğŸ“¡ Registered as {role}: {self.worker_id}")
                print(f"   GPU: {self.hardware['gpu']['name']}")
                print(f"   RAM: {self.hardware['ram_gb']}GB")
                print(f"   CPU: {self.hardware['cpu_name']} ({self.hardware['cpu_cores']} cores)")
                return True
            else:
                print(f"âŒ Registration failed: {resp.status_code} {resp.text}")
                return False
        except Exception as e:
            print(f"âŒ Cannot reach server: {e}")
            return False

    def send_heartbeat(self) -> Optional[Dict]:
        """Send heartbeat to orchestrator via HTTP."""
        try:
            usage = get_resource_usage()
            training_info = {}
            if self.current_job:
                training_info = {
                    "is_training": True,
                    "job_id": self.current_job.get("job_id"),
                    "layer_name": self.current_job.get("layer_name", ""),
                }

            resp = requests.post(
                f"{self.server}/api/v1/orchestrator/workers/heartbeat",
                json={
                    "worker_id": self.worker_id,
                    "status": "training" if self.current_job else "online",
                    "usage": usage,
                    "training": training_info,
                },
                headers=self.headers,
                timeout=10,
            )
            if resp.status_code == 200:
                data = resp.json()
                # Check for commands from server
                if data.get("command"):
                    self._handle_command(data["command"], data.get("params", {}))
                return data
            elif resp.status_code == 404:
                # Server restarted â€” auto re-register
                print("âš ï¸ Heartbeat 404 â€” server restarted. Re-registering...")
                self.register()
            return None
        except Exception:
            return None

    def poll_for_job(self) -> Optional[Dict]:
        """Poll orchestrator for next available job."""
        if self.current_job:
            return None

        # Check resource limits before accepting
        usage = get_resource_usage()
        if usage["cpu_percent"] > self.max_cpu:
            return None
        if usage["ram_percent"] > self.max_ram:
            return None
        if usage["gpu_percent"] > self.max_gpu:
            return None

        try:
            resp = requests.get(
                f"{self.server}/api/v1/orchestrator/jobs/next",
                params={
                    "worker_id": self.worker_id,
                    "labels": ",".join(self.labels),
                },
                headers=self.headers,
                timeout=10,
            )
            if resp.status_code == 200:
                data = resp.json()
                job = data.get("job")
                if job:
                    print(f"ğŸ“‹ Got job: {job['name']} [{job['job_id']}]")
                    return job
            return None
        except Exception:
            return None

    def execute_job(self, job: Dict[str, Any]):
        """Execute a training job."""
        self.current_job = job
        job_id = job["job_id"]
        print(f"ğŸš€ Executing: {job['name']}")

        try:
            command = job.get("command", "")
            use_shell = job.get("shell", False)

            if not command:
                # Default: run GPU-intensive training
                layer = job.get("layer_name", "council")
                config = job.get("config", {})
                epochs = config.get("epochs", 50)

                # Use gpu_trainer.py for real intensive training
                trainer_path = self.data_dir.parent / "hierarchy" / "gpu_trainer.py"
                if not trainer_path.exists():
                    trainer_path = Path(__file__).parent.parent / "hierarchy" / "gpu_trainer.py"

                command = (
                    f"{sys.executable} {trainer_path} "
                    f"--layer {layer} --epochs {epochs} "
                    f"--server {self.server} "
                    f"--token {self.token} "
                    f"--job-id {job_id} "
                    f"--worker-id {self.worker_id}"
                )
                use_shell = True  # Must use shell for complex command string

            result = subprocess.run(
                command if use_shell else command.split(),
                shell=use_shell,
                capture_output=True, text=True,
                timeout=7200,  # 2 hours max per job
                cwd=str(self.data_dir),
            )

            # Upload logs
            self._upload_log(job_id, result.stdout[-2000:] if result.stdout else "")
            if result.stderr:
                self._upload_log(job_id, f"STDERR: {result.stderr[-1000:]}")
                if result.returncode != 0:
                    print(f"âš ï¸ Job stderr: {result.stderr[-500:]}")

            # Report completion
            metrics = {
                "exit_code": result.returncode,
                "duration_seconds": 0,
            }

            if result.returncode == 0:
                self._complete_job(job_id, metrics)
                # Upload any generated checkpoints
                self._upload_checkpoints(job_id)
            else:
                self._fail_job(job_id, f"Exit code: {result.returncode}")

        except subprocess.TimeoutExpired:
            self._fail_job(job_id, "Timeout: exceeded 2 hours")
        except Exception as e:
            self._fail_job(job_id, str(e))
        finally:
            self.current_job = None

    def _complete_job(self, job_id: str, metrics: Dict):
        try:
            requests.post(
                f"{self.server}/api/v1/orchestrator/jobs/{job_id}/complete",
                params={"worker_id": self.worker_id, **{f"metrics[{k}]": v for k, v in metrics.items()}},
                json=metrics,
                headers=self.headers,
                timeout=10,
            )
            print(f"âœ… Job completed: {job_id}")
        except Exception as e:
            print(f"âš ï¸ Failed to report completion: {e}")

    def _fail_job(self, job_id: str, error: str):
        try:
            requests.post(
                f"{self.server}/api/v1/orchestrator/jobs/{job_id}/fail",
                params={"worker_id": self.worker_id, "error": error},
                headers=self.headers,
                timeout=10,
            )
            print(f"âŒ Job failed: {job_id} â€” {error}")
        except Exception:
            pass

    def _upload_log(self, job_id: str, line: str):
        try:
            requests.post(
                f"{self.server}/api/v1/orchestrator/jobs/{job_id}/log",
                params={"line": line[:2000]},
                headers=self.headers,
                timeout=5,
            )
        except Exception:
            pass

    def _upload_checkpoints(self, job_id: str):
        """Upload any new checkpoint files for this job."""
        for f in self.checkpoints_dir.iterdir():
            if f.is_file() and f.stat().st_mtime > time.time() - 3600:
                try:
                    with open(f, "rb") as fh:
                        requests.post(
                            f"{self.server}/api/v1/orchestrator/jobs/{job_id}/artifacts/upload",
                            files={"file": (f.name, fh)},
                            headers={"X-Orchestrator-Token": self.token},
                            timeout=60,
                        )
                    print(f"ğŸ“¤ Uploaded: {f.name}")
                except Exception as e:
                    print(f"âš ï¸ Upload failed: {f.name} â€” {e}")

    def _handle_command(self, command: str, params: Dict):
        """Handle a command from the orchestrator."""
        print(f"ğŸ“¨ Command: {command}")

        if command == "stop_job":
            if self.training_process:
                self.training_process.terminate()
                self.current_job = None

        elif command == "throttle":
            print(f"âš ï¸ Throttled: {params.get('message', '')}")
            # Reduce resource usage
            self.max_cpu = min(self.max_cpu, 60)
            self.max_gpu = min(self.max_gpu, 50)

        elif command == "update":
            print("ğŸ”„ Updating worker script...")
            self._self_update()

        elif command == "restart":
            print("ğŸ”„ Restarting...")
            os.execv(sys.executable, [sys.executable] + sys.argv)

        elif command == "shutdown":
            print("â¹ï¸ Shutting down...")
            self.running = False

    def _self_update(self):
        """Download latest worker script from server."""
        try:
            resp = requests.get(
                f"{self.server}/api/v1/orchestrator/worker-script",
                timeout=10,
            )
            if resp.status_code == 200:
                script_path = Path(__file__).resolve()
                script_path.write_text(resp.text)
                print("âœ… Updated. Restarting...")
                os.execv(sys.executable, [sys.executable] + sys.argv)
        except Exception as e:
            print(f"âš ï¸ Update failed: {e}")

    async def websocket_loop(self):
        """Maintain WebSocket connection to orchestrator."""
        ws_url = self.server.replace("https://", "wss://").replace("http://", "ws://")
        ws_url = f"{ws_url}/api/v1/orchestrator/ws/{self.worker_id}?token={self.token}"

        while self.running:
            try:
                async with websockets.connect(ws_url, ping_interval=20, ping_timeout=10) as ws:
                    self.ws = ws
                    self.reconnect_delay = 5
                    print(f"ğŸ”Œ WebSocket connected")

                    while self.running:
                        try:
                            # Send heartbeat
                            usage = get_resource_usage()
                            await ws.send(json.dumps({
                                "type": "heartbeat",
                                "status": "training" if self.current_job else "online",
                                "usage": usage,
                                "training": {
                                    "is_training": bool(self.current_job),
                                    "job_id": self.current_job.get("job_id") if self.current_job else None,
                                },
                            }))

                            # Wait for response or incoming command
                            try:
                                msg = await asyncio.wait_for(ws.recv(), timeout=self.heartbeat_interval)
                                data = json.loads(msg)

                                if data.get("type") == "command":
                                    self._handle_command(data["command"], data.get("params", {}))
                                elif data.get("type") == "new_job" and not self.current_job:
                                    job = data.get("job")
                                    if job:
                                        asyncio.get_event_loop().run_in_executor(None, self.execute_job, job)

                            except asyncio.TimeoutError:
                                pass

                        except websockets.ConnectionClosed:
                            break

            except Exception as e:
                self.ws = None
                if self.running:
                    print(f"ğŸ”Œ WebSocket disconnected. Retry in {self.reconnect_delay}s...")
                    await asyncio.sleep(self.reconnect_delay)
                    self.reconnect_delay = min(self.reconnect_delay * 1.5, 60)

    async def http_heartbeat_loop(self):
        """Fallback: HTTP heartbeat if WebSocket is down."""
        while self.running:
            if not self.ws:
                self.send_heartbeat()
            await asyncio.sleep(self.heartbeat_interval)

    async def job_polling_loop(self):
        """Poll for new jobs periodically."""
        while self.running:
            if not self.current_job:
                job = self.poll_for_job()
                if job:
                    loop = asyncio.get_event_loop()
                    loop.run_in_executor(None, self.execute_job, job)
            await asyncio.sleep(10)

    async def run(self):
        """Main run loop."""
        print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘     ğŸ”§ BI-IDE Worker Agent v1.0.0       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  Server: {self.server:<31s}â•‘
â•‘  Worker: {self.worker_id:<31s}â•‘
â•‘  Labels: {','.join(self.labels):<31s}â•‘
â•‘  GPU:    {self.hardware['gpu']['name'][:31]:<31s}â•‘
â•‘  RAM:    {self.hardware['ram_gb']}GB{' '*(28-len(str(self.hardware['ram_gb'])))}â•‘
â•‘  CPU:    {self.hardware['cpu_cores']} cores{' '*(25-len(str(self.hardware['cpu_cores'])))}â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """)

        # Register with retry
        for attempt in range(10):
            if self.register():
                break
            wait = min(5 * (attempt + 1), 60)
            print(f"â³ Retrying in {wait}s... (attempt {attempt+1}/10)")
            await asyncio.sleep(wait)
        else:
            print("âŒ Failed to register after 10 attempts. Exiting.")
            return

        # Run all loops
        tasks = [
            asyncio.create_task(self.websocket_loop()),
            asyncio.create_task(self.http_heartbeat_loop()),
            asyncio.create_task(self.job_polling_loop()),
        ]

        # Handle graceful shutdown
        def signal_handler(sig, frame):
            print("\nâ¹ï¸ Shutting down gracefully...")
            self.running = False
            for t in tasks:
                t.cancel()

        signal.signal(signal.SIGINT, signal_handler)
        signal.signal(signal.SIGTERM, signal_handler)

        try:
            await asyncio.gather(*tasks, return_exceptions=True)
        except asyncio.CancelledError:
            pass

        print("ğŸ‘‹ Worker stopped.")


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ CLI â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    parser = argparse.ArgumentParser(description="BI-IDE Worker Agent")
    parser.add_argument("--server", default="https://bi-iq.com", help="Orchestrator server URL")
    parser.add_argument("--token", default="", help="Orchestrator token")
    parser.add_argument("--labels", default="cpu", help="Comma-separated labels (e.g., gpu,rtx5090,primary)")
    parser.add_argument("--worker-id", default="", help="Worker ID (default: hostname)")
    parser.add_argument("--max-cpu", type=float, default=90, help="Max CPU usage %")
    parser.add_argument("--max-gpu", type=float, default=95, help="Max GPU usage %")
    parser.add_argument("--max-ram", type=float, default=85, help="Max RAM usage %")
    parser.add_argument("--heartbeat", type=int, default=30, help="Heartbeat interval seconds")
    args = parser.parse_args()

    agent = WorkerAgent(
        server_url=args.server,
        token=args.token,
        labels=args.labels.split(","),
        worker_id=args.worker_id,
        max_cpu=args.max_cpu,
        max_gpu=args.max_gpu,
        max_ram=args.max_ram,
        heartbeat_interval=args.heartbeat,
    )

    asyncio.run(agent.run())


if __name__ == "__main__":
    main()
