"""
ğŸ§  Real Training System - Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ
ÙƒÙ„ Ø·Ø¨Ù‚Ø© ØªØ¯Ø±Ø¨ Ù†Ù…ÙˆØ°Ø¬Ù‡Ø§ Ø§Ù„Ø®Ø§Øµ Ø¨Ø´ÙƒÙ„ Ø£ÙˆØªÙˆÙ…Ø§ØªÙŠÙƒÙŠ
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
import json
import os
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† GPU
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸ® Using device: {DEVICE}")
if torch.cuda.is_available():
    print(f"ğŸ’¾ GPU: {torch.cuda.get_device_name(0)}")
    print(f"ğŸ“Š VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")


class LayerDataset(Dataset):
    """Dataset Ù„ÙƒÙ„ Ø·Ø¨Ù‚Ø© Ø­Ø³Ø¨ Ø§Ø®ØªØµØ§ØµÙ‡Ø§"""
    
    def __init__(self, layer_name: str, data_path: str = "./data"):
        self.layer_name = layer_name
        self.data_path = data_path
        self.samples = []
        self.labels = []
        self._load_data()
    
    def _load_data(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ø®ØªØµØ§Øµ Ø§Ù„Ø·Ø¨Ù‚Ø©"""
        if self.layer_name == "erp_accounting":
            self._load_erp_data()
        elif self.layer_name == "erp_inventory":
            self._load_inventory_data()
        elif self.layer_name == "ide_code":
            self._load_code_data()
        elif self.layer_name == "ide_copilot":
            self._load_copilot_data()
        elif self.layer_name == "council_strategy":
            self._load_strategy_data()
        elif self.layer_name == "scouts_intel":
            self._load_intel_data()
        else:
            # Ø¨ÙŠØ§Ù†Ø§Øª Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ø·Ø¨Ù‚Ø§Øª Ø§Ù„Ø£Ø®Ø±Ù‰
            self._generate_synthetic_data()
    
    def _load_erp_data(self):
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø­Ø§Ø³Ø¨Ø©"""
        try:
            with open(f"{self.data_path}/erp_basic.json", "r") as f:
                data = json.load(f)
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙÙˆØ§ØªÙŠØ± Ù„Ø£Ø±Ù‚Ø§Ù…
            for inv in data.get("invoices", []):
                features = [
                    inv.get("amount", 0) / 10000,  # normalizing
                    inv.get("tax", 0) / 1000,
                    inv.get("total", 0) / 10000,
                    1 if inv.get("status") == "paid" else 0
                ]
                self.samples.append(features)
                self.labels.append(1 if inv.get("status") == "paid" else 0)
        except:
            self._generate_synthetic_data()
    
    def _load_inventory_data(self):
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø®Ø²ÙˆÙ†"""
        try:
            with open(f"{self.data_path}/erp_advanced.json", "r") as f:
                data = json.load(f)
            for item in data.get("inventory", []):
                features = [
                    item.get("quantity", 0) / 1000,
                    item.get("unit_price", 0) / 1000,
                    item.get("reorder_point", 0) / 100,
                    item.get("stock_alert", 0)
                ]
                self.samples.append(features)
                self.labels.append(item.get("stock_alert", 0))
        except:
            self._generate_synthetic_data()
    
    def _load_code_data(self):
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒÙˆØ¯"""
        try:
            # Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠØ©
            code_dir = Path("./ide")
            if code_dir.exists():
                for file in code_dir.rglob("*.py"):
                    content = file.read_text()
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ features Ù…Ù† Ø§Ù„ÙƒÙˆØ¯
                    lines = len(content.split('\n'))
                    chars = len(content)
                    functions = content.count('def ')
                    classes = content.count('class ')
                    
                    features = [lines / 1000, chars / 10000, functions / 50, classes / 20]
                    self.samples.append(features)
                    self.labels.append(1 if functions > 5 else 0)  # complex or simple
        except:
            self._generate_synthetic_data()
    
    def _load_copilot_data(self):
        """Ø¨ÙŠØ§Ù†Ø§Øª Copilot"""
        # ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Ø§Ù„Ù‚ÙˆØ§Ù„Ø¨
        templates = [
            "def function():", "class ClassName:", "import module",
            "for i in range:", "if condition:", "try: except:"
        ]
        for i, template in enumerate(templates):
            features = [ord(c) % 256 / 255 for c in template[:20]]
            features += [0] * (20 - len(features))  # padding
            self.samples.append(features[:4])  # Ù†Ø®ØªØµØ± Ù„Ù€ 4 features
            self.labels.append(i % 2)
    
    def _load_strategy_data(self):
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© Ø§Ù„Ù…Ø¬Ù„Ø³"""
        decisions = [
            [0.8, 0.2, 0.9, 0.7],  # Ø§Ø³ØªØ«Ù…Ø§Ø±
            [0.3, 0.8, 0.4, 0.6],  # ØªØ­ÙØ¸
            [0.9, 0.1, 0.8, 0.9],  # ØªÙˆØ³Ø¹
            [0.5, 0.5, 0.5, 0.5],  # Ù…Ø­Ø§ÙŠØ¯
        ]
        for i, decision in enumerate(decisions):
            for _ in range(10):  # ØªÙƒØ±Ø§Ø± Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
                noise = np.random.normal(0, 0.05, 4)
                self.samples.append(np.clip(np.array(decision) + noise, 0, 1).tolist())
                self.labels.append(i)
    
    def _load_intel_data(self):
        """Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙƒØ´Ø§ÙØ©"""
        # Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ø³ØªØ®Ø¨Ø§Ø±Ø§ØªÙŠØ© ( threats, opportunities, etc)
        for i in range(100):
            features = np.random.rand(4).tolist()
            self.samples.append(features)
            self.labels.append(1 if features[0] > 0.7 else 0)  # high priority
    
    def _generate_synthetic_data(self):
        """ØªÙˆÙ„ÙŠØ¯ Ø¨ÙŠØ§Ù†Ø§Øª ØµÙ†Ø§Ø¹ÙŠØ© Ù„Ù„Ø§Ø®ØªØ¨Ø§Ø±"""
        for i in range(100):
            features = np.random.rand(4).tolist()
            self.samples.append(features)
            self.labels.append(np.random.randint(0, 2))
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        return torch.FloatTensor(self.samples[idx]), torch.LongTensor([self.labels[idx]])[0]


class LayerModel(nn.Module):
    """Ù†Ù…ÙˆØ°Ø¬ Ù„ÙƒÙ„ Ø·Ø¨Ù‚Ø© - Transformer ØµØºÙŠØ±"""
    
    def __init__(self, input_size: int = 4, hidden_size: int = 128, num_classes: int = 2):
        super().__init__()
        self.encoder = nn.Sequential(
            nn.Linear(input_size, hidden_size),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_size, hidden_size // 2),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(hidden_size // 2, num_classes)
        )
    
    def forward(self, x):
        return self.encoder(x)


class LayerTrainer:
    """Ù…Ø¯Ø±Ø¨ ÙƒÙ„ Ø·Ø¨Ù‚Ø©"""
    
    def __init__(self, layer_name: str):
        self.layer_name = layer_name
        self.model = LayerModel().to(DEVICE)
        self.dataset = LayerDataset(layer_name)
        self.dataloader = DataLoader(
            self.dataset, 
            batch_size=32, 
            shuffle=True,
            num_workers=0  # Ù„ØªØ¬Ù†Ø¨ Ù…Ø´Ø§ÙƒÙ„ multiprocessing
        )
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        self.criterion = nn.CrossEntropyLoss()
        
        self.epoch = 0
        self.best_loss = float('inf')
        self.training = False
        self.thread = None
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        self.stats = {
            "loss": 0.0,
            "accuracy": 0.0,
            "samples_trained": 0,
            "last_update": None
        }
        
        print(f"ğŸ§  {layer_name}: {len(self.dataset)} samples loaded")
    
    def train_epoch(self):
        """ØªØ¯Ø±ÙŠØ¨ epoch ÙˆØ§Ø­Ø¯"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (data, target) in enumerate(self.dataloader):
            data, target = data.to(DEVICE), target.to(DEVICE)
            
            self.optimizer.zero_grad()
            output = self.model(data)
            loss = self.criterion(output, target)
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            _, predicted = output.max(1)
            total += target.size(0)
            correct += predicted.eq(target).sum().item()
            
            self.stats["samples_trained"] += data.size(0)
        
        avg_loss = total_loss / len(self.dataloader)
        accuracy = 100. * correct / total
        
        self.stats["loss"] = avg_loss
        self.stats["accuracy"] = accuracy
        self.stats["last_update"] = datetime.now().isoformat()
        
        self.epoch += 1
        
        return avg_loss, accuracy
    
    def training_loop(self):
        """Ø­Ù„Ù‚Ø© Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ù…Ø³ØªÙ…Ø±Ø©"""
        print(f"ğŸš€ Starting training for {self.layer_name}")
        
        while self.training:
            loss, accuracy = self.train_epoch()
            
            if self.epoch % 10 == 0:
                print(f"ğŸ“Š {self.layer_name} - Epoch {self.epoch}: Loss={loss:.4f}, Acc={accuracy:.2f}%")
            
            # Ø­ÙØ¸ Ø£ÙØ¶Ù„ Ù†Ù…ÙˆØ°Ø¬
            if loss < self.best_loss:
                self.best_loss = loss
                self.save_checkpoint()
            
            time.sleep(0.1)  # ÙØ§ØµÙ„ Ø¨Ø³ÙŠØ·
        
        print(f"â¹ï¸ Training stopped for {self.layer_name}")
    
    def start(self):
        """Ø¨Ø¯Ø¡ Ø§Ù„ØªØ¯Ø±ÙŠØ¨ ÙÙŠ Thread Ù…Ù†ÙØµÙ„"""
        if self.training:
            return
        
        self.training = True
        self.thread = threading.Thread(target=self.training_loop)
        self.thread.daemon = True
        self.thread.start()
    
    def stop(self):
        """Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        self.training = False
        if self.thread:
            self.thread.join(timeout=5)
    
    def save_checkpoint(self):
        """Ø­ÙØ¸ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        checkpoint_dir = Path(f"./checkpoints/{self.layer_name}")
        checkpoint_dir.mkdir(parents=True, exist_ok=True)
        
        torch.save({
            'epoch': self.epoch,
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'best_loss': self.best_loss,
            'stats': self.stats
        }, checkpoint_dir / "best_model.pt")
    
    def load_checkpoint(self):
        """ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬"""
        checkpoint_path = Path(f"./checkpoints/{self.layer_name}/best_model.pt")
        if checkpoint_path.exists():
            checkpoint = torch.load(checkpoint_path)
            self.model.load_state_dict(checkpoint['model_state_dict'])
            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            self.epoch = checkpoint['epoch']
            self.best_loss = checkpoint['best_loss']
            self.stats = checkpoint['stats']
            print(f"ğŸ“‚ Loaded checkpoint for {self.layer_name} (epoch {self.epoch})")


class RealTrainingSystem:
    """Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¯Ø±ÙŠØ¨ Ø§Ù„Ø­Ù‚ÙŠÙ‚ÙŠ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„"""
    
    def __init__(self):
        self.layers = {}
        self.is_running = False
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¯Ø±Ø¨ Ù„ÙƒÙ„ Ø·Ø¨Ù‚Ø©
        layer_names = [
            "erp_accounting",
            "erp_inventory", 
            "erp_hr",
            "ide_code",
            "ide_copilot",
            "council_strategy",
            "scouts_intel",
            "meta_optimization",
            "execution_planning",
            "guardian_security"
        ]
        
        print("ğŸ—ï¸ Initializing Real Training System...")
        for name in layer_names:
            self.layers[name] = LayerTrainer(name)
        
        print(f"âœ… {len(self.layers)} trainers ready")
    
    def start_all(self):
        """Ø¨Ø¯Ø¡ ØªØ¯Ø±ÙŠØ¨ ÙƒÙ„ Ø§Ù„Ø·Ø¨Ù‚Ø§Øª"""
        print("ğŸš€ Starting training for all layers...")
        self.is_running = True
        
        for name, trainer in self.layers.items():
            trainer.start()
            time.sleep(0.5)  # ÙØ§ØµÙ„ Ø¨ÙŠÙ† ÙƒÙ„ Ø·Ø¨Ù‚Ø©
        
        print("âœ… All layers training started!")
    
    def stop_all(self):
        """Ø¥ÙŠÙ‚Ø§Ù ÙƒÙ„ Ø§Ù„ØªØ¯Ø±ÙŠØ¨"""
        print("â¹ï¸ Stopping all training...")
        self.is_running = False
        
        for trainer in self.layers.values():
            trainer.stop()
        
        print("âœ… All training stopped")
    
    def get_status(self):
        """Ø§Ù„Ø­Ø§Ù„Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©"""
        gpu_info = {}
        if torch.cuda.is_available():
            gpu_info = {
                "name": torch.cuda.get_device_name(0),
                "utilization": torch.cuda.utilization(),
                "memory_used": torch.cuda.memory_allocated() / 1e9,
                "memory_total": torch.cuda.get_device_properties(0).total_memory / 1e9,
                "temperature": self._get_gpu_temp()
            }
        
        return {
            "is_training": self.is_running,
            "device": str(DEVICE),
            "gpu": gpu_info,
            "layers": {
                name: {
                    "epoch": trainer.epoch,
                    "loss": trainer.stats["loss"],
                    "accuracy": trainer.stats["accuracy"],
                    "samples": trainer.stats["samples_trained"],
                    "dataset_size": len(trainer.dataset)
                }
                for name, trainer in self.layers.items()
            }
        }
    
    def _get_gpu_temp(self):
        """Ù‚Ø±Ø§Ø¡Ø© Ø­Ø±Ø§Ø±Ø© GPU"""
        try:
            import pynvml
            pynvml.nvmlInit()
            handle = pynvml.nvmlDeviceGetHandleByIndex(0)
            return pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)
        except:
            return 0


# Singleton
training_system = RealTrainingSystem()

if __name__ == "__main__":
    # Ø§Ø®ØªØ¨Ø§Ø±
    system = RealTrainingSystem()
    system.start_all()
    
    try:
        while True:
            time.sleep(5)
            status = system.get_status()
            print(f"\nğŸ“Š GPU: {status['gpu'].get('utilization', 0)}% | "
                  f"Memory: {status['gpu'].get('memory_used', 0):.1f} GB")
            for name, stats in status["layers"].items():
                print(f"  {name}: Epoch {stats['epoch']}, Loss {stats['loss']:.4f}, Acc {stats['accuracy']:.2f}%")
    except KeyboardInterrupt:
        system.stop_all()
